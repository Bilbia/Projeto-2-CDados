{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beatriz Muniz de Castro e Silva\n",
    "\n",
    "Nicole Sarvasi Alves da Costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o intuito de destacar mensagens que designem o nome do produto, primeiro baixamos os *tweets* com o nome do filme Bacurau. Após, classificamos um por um entre \"relevante\" e \"irrelevantes\", tal classificação será explicitada mais adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer isso, utilizaremos o algoritmo \"Naive Bayes\", criado no século XVIII. Atualmente, esse classificador probabilístico tem sido utilizado na área de *Machine Learning* principalmente para a categorização de textos, determinação de e-mails SPAM, e até para medicina diagnóstica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o treinamento do cógigo, utilizamos uma base de 300 *tweets* para podermos implementar o classificador Naive-Bayes. Isso possibilitará verificarmos sua eficiência, uma vez que poderemos comparar as classificações feitas, com as previamente estabelecidas por nós."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classificação dos *tweets*:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Relevante**: mensagens que passem uma imagem positiva sobre o filme                    \n",
    "    **ex.:** \"Bacurau é um filme excelente!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Irrelevante**: mensagens que passem uma imagem negativa sobre o filme ou que não o caracterizem                   \n",
    "        **ex.:** \"O filme bacurau é péssimo\" ; \"Bacurau já está em cartaz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "#Instalando o pacote emoji para limpar mensagens\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#importando os pacotes necessários\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import functools\n",
    "import operator\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: @nicknennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'auth.pass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-3a68e2b1c78f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#leitura do arquivo no formato JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auth.pass'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auth.pass'"
     ]
    }
   ],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Identificador da conta no twitter: @nickcnennis\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'bacurau'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 700\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 500\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "\n",
    "#retira os retweets\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode='extended').items():  \n",
    "    if (not msg.retweeted) and ('RT' not in msg.full_text): \n",
    "        msgs.append(msg.full_text.lower())\n",
    "        i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Classificamos os *tweets* de treinamento individualmente no Excel, atribuindo 0 para \"irrelevante\" e 1 para \"relevante\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo excel\n",
    "treino = pd.read_excel(\"bacurau.xlsx\", \"Treinamento\") #tabela da parte de treinamento do excel\n",
    "teste = pd.read_excel(\"bacurau.xlsx\", \"Teste\") #tabela da parte de teste do excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a montagem do classificador Naive-Bayes, primeiramente limpamos os dados. Ou seja, corrigimos os espaços entre as palavras e tiramos as pontuações, tendo o cuidado de manter os emojis, os quais podem ser cruciais para determinar algum tipo de sentimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if not word.startswith('https'))\n",
    "    \n",
    "    text_split_emoji = emoji.get_emoji_regexp().split(text)\n",
    "    text_split_whitespace = [substr.split() for substr in text_split_emoji]\n",
    "    text_split = functools.reduce(operator.concat, text_split_whitespace)\n",
    "    text = ' '.join(word for word in text_split)\n",
    "    \n",
    "    punctuation = '[!-/.:?;@]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    nova_linha = '[\\n]'\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    text_subbed = re.sub(nova_linha, \" \", text_subbed)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, criamos uma lista com os *tweets* de teste limpos e aproveitamos para deixar todas as palavras em letra minúscula, o que nos ajudará no momento de identificar as frequências das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar uma lista com os tweets de teste limpos\n",
    "teste_t = pd.Series(teste[\"Teste\"])\n",
    "teste_limpo = []\n",
    "for i in teste_t:\n",
    "    teste_limpo.append(cleanup(i.lower()))\n",
    "# teste_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar uma lista com os tweets de treinamento limpos\n",
    "treino_s = pd.Series(treino[\"Treinamento\"])\n",
    "treino_limpo = []\n",
    "for i in treino_s:\n",
    "    treino_limpo.append(cleanup(str(i).lower()))\n",
    "# treino_limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra limpeza que poderia ser feita para o melhor rendimento do nosso classificador seria a retirada de artigos, que não se mostram cruciais para a classificação de sentimento de cada *tweet*. Para isso, seria eficaz uma função a qual retirasse palavras de até duas letras, este processo serviria também para a retirada de erros possivelmente feitos no momento de escrita nos textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequência relativa total das palavras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bacurau            0.059806\n",
       "de                 0.044272\n",
       "rt                 0.021100\n",
       "e                  0.021100\n",
       "a                  0.019288\n",
       "é                  0.017864\n",
       "que                0.017735\n",
       "tirei              0.015534\n",
       "o                  0.015146\n",
       "eu                 0.012816\n",
       "você               0.011133\n",
       "do                 0.009968\n",
       "ver                0.009191\n",
       "pra                0.008932\n",
       "no                 0.008026\n",
       "um                 0.007896\n",
       "assistir           0.007896\n",
       "filme              0.007249\n",
       "não                0.007120\n",
       "uma                0.006861\n",
       "com                0.006731\n",
       "para               0.006731\n",
       "em                 0.006084\n",
       "da                 0.005955\n",
       "tem                0.005696\n",
       "gente              0.005437\n",
       "mas                0.005437\n",
       "qual               0.004919\n",
       "lunga              0.004531\n",
       "domingas           0.004531\n",
       "                     ...   \n",
       "lucasnunnes97      0.000129\n",
       "temática           0.000129\n",
       "clássico           0.000129\n",
       "😟                  0.000129\n",
       "cair               0.000129\n",
       "finja              0.000129\n",
       "sagrado            0.000129\n",
       "βαcυrαυ            0.000129\n",
       "essas              0.000129\n",
       "melted             0.000129\n",
       "rua                0.000129\n",
       "conte              0.000129\n",
       "barata             0.000129\n",
       "amigas             0.000129\n",
       "rápido             0.000129\n",
       "dando              0.000129\n",
       "bacurit            0.000129\n",
       "conturbada         0.000129\n",
       "tanta              0.000129\n",
       "iskindolele        0.000129\n",
       "passado            0.000129\n",
       "chegaram           0.000129\n",
       "espécie            0.000129\n",
       "promocional        0.000129\n",
       "felix              0.000129\n",
       "entendi            0.000129\n",
       "ansiosíssimaaaa    0.000129\n",
       "faca               0.000129\n",
       "companhia          0.000129\n",
       "adoro              0.000129\n",
       "Length: 1693, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino_t = (\" \").join(treino_limpo) #junta todos os tweets de treinamento em uma string só\n",
    "lista_relativa = treino_t.split() #divide a string pra fazer uma lista com cada palavra separadamente\n",
    "frequencia_absoluta = pd.Series(lista_relativa).value_counts()\n",
    "frequencia_relativa = pd.Series(lista_relativa).value_counts(True)\n",
    "frequencia_relativa #frequencia relativa total das palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequência relativa dos *tweets* relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bacurau           0.059778\n",
       "de                0.034291\n",
       "que               0.027340\n",
       "e                 0.024096\n",
       "o                 0.018999\n",
       "pra               0.018536\n",
       "ver               0.018072\n",
       "a                 0.016682\n",
       "assistir          0.014365\n",
       "filme             0.013438\n",
       "do                0.012975\n",
       "é                 0.012975\n",
       "eu                0.012512\n",
       "no                0.010658\n",
       "não               0.009268\n",
       "um                0.007414\n",
       "em                0.007414\n",
       "com               0.006951\n",
       "mas               0.006951\n",
       "cinema            0.006951\n",
       "me                0.006487\n",
       "mais              0.006487\n",
       "tem               0.005561\n",
       "bom               0.005097\n",
       "vou               0.005097\n",
       "sobre             0.005097\n",
       "uma               0.005097\n",
       "da                0.004634\n",
       "q                 0.004634\n",
       "vai               0.004634\n",
       "                    ...   \n",
       "pararem           0.000463\n",
       "sido              0.000463\n",
       "silveropereira    0.000463\n",
       "preço             0.000463\n",
       "gostou            0.000463\n",
       "exibidos          0.000463\n",
       "serem             0.000463\n",
       "indo              0.000463\n",
       "pelos             0.000463\n",
       "sombrios          0.000463\n",
       "festival          0.000463\n",
       "favorrt           0.000463\n",
       "top               0.000463\n",
       "lados             0.000463\n",
       "wotzik            0.000463\n",
       "trocado’          0.000463\n",
       "meter             0.000463\n",
       "serão             0.000463\n",
       "leao              0.000463\n",
       "filha             0.000463\n",
       "vez               0.000463\n",
       "texto             0.000463\n",
       "estarei           0.000463\n",
       "mto               0.000463\n",
       "consigo           0.000463\n",
       "retrato           0.000463\n",
       "loucura           0.000463\n",
       "amanhã            0.000463\n",
       "louca             0.000463\n",
       "adoro             0.000463\n",
       "Length: 878, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = treino.index[treino.Relevância == 1] #critério para selecionar só os tweets relevantes\n",
    "treino_r = treino.loc[rel, \"Treinamento\"]  #cria nova database com os tweets relevantes\n",
    "\n",
    "\n",
    "#frequência das palavras nos tweets relevantes\n",
    "treino_rt = treino_r.str.cat()\n",
    "treino_rt = cleanup(treino_rt.lower())\n",
    "lista_relevante = treino_rt.split()\n",
    "frequencia_absoluta = pd.Series(lista_relevante).value_counts()\n",
    "frequencia_rel_relevantes = pd.Series(lista_relevante).value_counts(True)\n",
    "frequencia_rel_relevantes #frequência relativa dos tweets relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequência relativa dos *tweets* irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bacurau           0.054954\n",
       "de                0.051858\n",
       "é                 0.021091\n",
       "e                 0.020511\n",
       "a                 0.020511\n",
       "que               0.014899\n",
       "tirei             0.014319\n",
       "você              0.014319\n",
       "o                 0.014125\n",
       "eu                0.011997\n",
       "do                0.009481\n",
       "para              0.009094\n",
       "um                0.008707\n",
       "uma               0.007933\n",
       "no                0.007546\n",
       "com               0.007159\n",
       "da                0.006966\n",
       "domingas          0.006772\n",
       "qual              0.006772\n",
       "lunga             0.006579\n",
       "não               0.006385\n",
       "gente             0.006192\n",
       "em                0.005998\n",
       "tem               0.005998\n",
       "personagem        0.005998\n",
       "ver               0.005805\n",
       "assistir          0.005805\n",
       "pra               0.005611\n",
       "se                0.005418\n",
       "filme             0.005224\n",
       "                    ...   \n",
       "acionar           0.000193\n",
       "júri              0.000193\n",
       "f…rt              0.000193\n",
       "high              0.000193\n",
       "conta             0.000193\n",
       "putz              0.000193\n",
       "editor            0.000193\n",
       "silvero           0.000193\n",
       "descobrimos       0.000193\n",
       "além              0.000193\n",
       "nadar             0.000193\n",
       "zadorarocha       0.000193\n",
       "camilamotad       0.000193\n",
       "oficialmente      0.000193\n",
       "grito             0.000193\n",
       "instagram         0.000193\n",
       "tony              0.000193\n",
       "davirochatirei    0.000193\n",
       "exposição         0.000193\n",
       "berrando          0.000193\n",
       "te…kkkkkk         0.000193\n",
       "aviso             0.000193\n",
       "colunista         0.000193\n",
       "querer            0.000193\n",
       "22h30             0.000193\n",
       "crise             0.000193\n",
       "chegamos          0.000193\n",
       "hojert            0.000193\n",
       "sanguevcs         0.000193\n",
       "🎼                 0.000193\n",
       "Length: 1244, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irel = treino.index[treino.Relevância == 0]\n",
    "treino_ir = treino.loc[irel, \"Treinamento\"]  #tweets irrelevantes\n",
    "\n",
    "#frequência das palavras nos tweets irrelevantes\n",
    "treino_irt = treino_ir.str.cat()\n",
    "treino_irt = cleanup(treino_irt.lower())\n",
    "lista_irrelevante = treino_irt.split()\n",
    "frequencia_absoluta = pd.Series(lista_irrelevante).value_counts()\n",
    "frequencia_rel_irrelevantes = pd.Series(lista_irrelevante).value_counts(True)\n",
    "frequencia_rel_irrelevantes #frequência relativa dos tweets irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinar as frequências acima é crucial para podermos calcular as probabilidades as quais serão utilizadas no método de Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quantidade de *tweets* relevantes e irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    354\n",
       "1    147\n",
       "Name: Relevância, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantidade_relevancia = treino.Relevância.value_counts()\n",
    "quantidade_relevancia #quantidade de tweets relevantes e irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porcentagem de *tweets* relevantes e irrelevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    70.658683\n",
       "1    29.341317\n",
       "Name: Relevância, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantidade_relevancia_pct = treino.Relevância.value_counts(True)*100\n",
    "quantidade_relevancia_pct #porcentagem dos tweets que são relevantes e irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lista com todas as palavras que aparecem nos *tweets* da nossa tabela de treinamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nossa', 'eu', 'desviei', 'muito', 'rápido', 'de', 'um', 'spoiler', 'bacurau', 'me', 'senti', 'ninja', 'rt', 'avokdoido', 'quem', 'nao', 'gostou', 'é', 'no', 'mínimo', 'do', 'pouco', 'nazista', 'sim', 'vi', 'ontem', 'com', 'a', 'viviane_cardoso', 'o', 'filme', 'fantástico', 'vale', 'pena', 'ver', 'se', 'você', 'tiver', 'mente', 'aberta', 'e', 'qualquer', 'coisa', 'que', 'faço', 'vivi', 'sempre', 'bom', 'companheira', 'filmes', 'vida', 'lutas', 'lt', '3', 'hoje', 'finalmente', 'vejo', 'será', 'consigo', 'chegar', 'até', 'sala', 'livre', 'tá', 'difícil', 'lzanin', 'texto', 'marcelo', 'coelho', 'chama', '‘bolsonarisno', 'sinal', 'trocado’', 'lembra', 'ideia', 'alguns', 'jornalistas', 'na', 'é…', 'diretor', 'joão', 'kleber', 'mendonça', 'filho', 'n', 'vou', 'conseguir', 'qual', 'desse', 'q', 'galera', 'ta', 'doida', 'achei', 'era', 'peixe', 'isso', 'vai', 'assistir', 'sai', 'maluco', 'todo', 'dia', 'bora', 'galeres', 'aproveitando', 'pra', 'divulgar', 'melhor', '2019', 'personagem', 'tirei', 'lunga', 'aí', 'cara', 'já', 'assistiu', '𝐉𝐚́', '𝐚𝐬𝐬𝐢𝐬𝐭𝐢𝐮', '𝐁𝐚𝐜𝐮𝐫𝐚𝐮', 'jά', 'αssιsτιυ', 'βαcυrαυ', '𝕵𝖆́', '𝖆𝖘𝖘𝖎𝖘𝖙𝖎𝖚', '𝕭𝖆𝖈𝖚𝖗𝖆𝖚', 'jᴀ́', 'ᴀssɪsᴛɪᴜ', 'bᴀᴄᴜʀᴀᴜ﹖', 'foda', 'omelete', 'ainda', 'foi', 'visto', 'por', 'mais', '130', 'mil', 'pessoas', 'diariosm', 'sucesso', 'público', 'não', 'deve', 'ser', 'exibido', 'nos', 'cinemas', 'santa', 'maria', 'aparentemente', 'só', 'ao', 'nesse', 'país', 'sábado', 'to', 'ansiosíssimaaaa', 'fds', 'passa', 'saindo', 'cedo', 'da', 'faculdade', 'correndo', 'kmendoncafilho', 'cine', 'arte', 'uff', 'uma', 'equipada', 'como', 'poucas', 'numa', 'universidade', 'pública', 'lotada', 'estudantes', 'para', 'brasi…', 'fazendo', 'propaganda', 'grandao', 'pro', 'uber', 'aqui', 'ele', 'disse', 'domingo', 'perfeito', 'poxa', 'alguém', 'leva', 'psousadealmeida', 'tenho', 'novo', 'tarantino', 'it', 'aaaaaa', 'favor', 'parem', 'falar', 'às', '20', '40', 'chamem', 'sabe', 'bacurinha', 'thalitamari', '_meirabeatriz', 'menina', 'agora', 'tu', 'tava', 'falando', 'kkkkkk', 'apois', 'gente', 'faz', 'nem', 'treinamento', 'pq', 'esse', 'teria', 'oposição', 'queria', 'ter', 'dinheiro', 'wwwmlna', 'algum', 'homem', 'feminista', 'online', 'disposto', 'dar', 'professora', 'didatica', 'perguntando', 'turma', 'viu', 'mas', 'vocês', 'foram', 'gostei', 'tiduraes', 'em', '31°', 'top', '250', 'letterboxd', 'lindo', 'comigo', 'anarcofino', 'minha', 'ex', 'cineasta', 'cheia', 'dos', 'contatos', 'manda', 'mensagem', 'digo', 'com…', 'hortawitch', 'assistindo', 'estou', 'vivendo', 'ou', 'apenas', 'curtindo', 'retwittando', 'repostando', 'coisas', 'sobre', 'baruchinha', 'tem', 'acho', 'amiga', 'pfvr', '2', 'pode', 'ganhar', 'prêmio', 'ano', 'beijos', 'sabia', 'karine', 'teles', 'dona', 'meu', 'c', 'susto', 'thread', 'deliciosa', 'tesão', 'estreia', '10de10', 'caazalberto', 'escreveu', 'momento', 'boca', 'garotada', 'incomodando', 'gado', '🔥', '🐂', 'review', 'completo', 'site', '👉', 'affandre', 'tanto', 'invisível', 'serão', 'exibidos', 'festival', 'toronto', 'grandes', 'veículos', 'temporada', 'premiaç…', 'aconteceu', 'tudo', 'ruim', 'clap', 'existem', 'imperdíveis', 'pela', 'relevância', 'temática', 'admiráveis', 'pelo', 'significado', 'cultural', 'memoráveis', 'serem', 'emblemáticos', 'tendo', 'monitoria', 'exposição', 'gringos', 'depois', 'matei', 'todos', 'sujei', 'os', 'quadros', 'sangue', 'tempos', 'sombrios', 'apreciar', 'boa', 'resistência', '07', 'setembro', 'poços', 'caldas', 'estarei', 'lá', 'ingressos', 'comprados', 'quero', 'mto', 'ir', 'caralhoo', 'preciso', 've', 'namoral', 'assistam', 'pqp', 'temia', 'veio', 'cinéfilo', 'perto', 'mim', 'tão', 'more', 'bater', 'palma', 'tailandês', 'for', 'va', 'paz', 'casa', 'caralho', 'fica', 'começa', 'pensar', 'cinema', 'cada', 'pensada', 'dá', 'baixar', 'minhas', 'expectativas', 'porque', 'gosto', 'expectativa', 'alta', 'assim', 'ajuda', 'tempo', 'louvando', 'vcs', 'ficam', 'ai', 'oxewill94', 'vez', 'bicho', 'avengers', 'adoro', 'consumo', 'brasileiro', 'saco', 'cheio', 'pararem', 'fico', 'quando', 'falam', 'insistentemente', 'outra', 'diegoquaglia2', 'sei', 'odeio', 'black', 'mirror', 'comparação', '…', 'constrangedor', 'existir', 'instagram', 'chamado', 'bacurau_memes', 'deus', 'faça', 'cair', 'tempi', 'ain', 'aguento', 'ouvir', 'esses', 'porra', 'entulhando', 'timeline', 'herói', 'hollywood', 'ok', 'falo', 'nada', 'deixa', 'exaltar', 'daqui', 'pouquinho', 'tb', 'fazer', 'meus', 'amigos', 'assistirem', 'vão', 'vamos', 'la', 'mudar', 'pais', 'eh', 'possivel', 'eles', 'tenham', 'realmente', 'tirado', 'edir', 'macedo', 'passando', '50', 'semana', 'dias_ligia', 'ninguém', 'perguntou', 'ameei', 'amor', 'bolha', 'hype', 'está', 'maior', 'cmg', 'sido', 'lana', 'del', 'rey', 'harry', 'styles', 'errado', 'nenhum', 'deles', 'desisti', 'isto', 'capitulo', 'ova', 'apoiar', 'esganado', 'pelos', 'norte', 'americanos', 'kkkkkkkk', 'disseram', 'assisti', 'lo', 'vem', 'entrar', 'internet', 'alheia', 'outro', 'tbm', 'aquarius', 'renatoxavoso', 'kléber', 'entre', 'coma', 'cu', 'toda', 'família', 'obrigado', 'demais', 'inuyalice', 'fui', '99', 'certeza', 'ia', 'sair', 'tiraram', 'yesterday', 'amigo', 'sessão', 'das', '9', 'teve', 'alguem', 'amanha', 'stargirllv', 'carai', 'bê', 'indo', 'yuri_reinaldo', '16', 'horas', 'pensando', 'cinesiageek', 'deveria', 'elogio', 'tipo', 'mó', 'comédia', 'ação', 'drama', 'it2', 'mt', 'ansiosa', 'principalmente', 'as', 'meninas', '🥳', 'aula', 'vsffffffff', 'lugar', 'pros', 'lados', 'zona', 'madureira', 'shopping', 'rei', 'leao', 'programado', 'meier', 'sessao', '21h', 'noite', 'puta', 'excelente', 'saudável', 'catarse', 'aliás', 'mesmo', 'oxigene', 'maoleskine', 'maratonar', 'breve', 'again', 'primeira', 'lançamento', 'determina', 'quanto', 'cartaz', 'essa', 'lançado', 'maravilhoso', 'mundo', 'sério', 'brasileiros', '❤', '️', 'sopranine', 'ali', 'juntas', 'moskito', 'recebendo', 'mandar', 'grupo', 'dividido', 'amou', 'odiou', 'idosas', 'estavam', 'gostaram', 'admitiram', 'bem', 'feito', 'wotzik', 'brasil', 'urgente', 'vivam', 'necessário', 'iskindolele', 'estava', 'obcecado', 'passava', '80', 'outros', 'torcia', 'falasse', 'sobre…', 'porém', 'afirmo', 'tranquilidade', 'milenio', 'veja', 'molena', 'incentive', 'nacional', 'meter', 'doido', 'logo', 'iguatemi', 'antes', 'fique', 'sem', 'minh', 'dando', 'palestra', 'pessoal', 'fez', 'trilha', 'sonora', 'mimos', 'pai', 'aquelacristiana', 'fãs', '=', 'melhores', 'parece', 'infinitamente', 'interessante', 'rodrigoazo', 'olha', 'motivo', 'vermos', 'filmaço', 'ode', 'nosso', 'sobretudo', 'valente', 'povo', 'nordestino', 'sensação', 'reencontro', 'cultura', 'retrato', 'histórico', 'majestoso', 'viva', 'chegou', 'jundiaí', 'sexo', 'sagrado', 'seu', 'corpo', 'templo', 'compartilhá', 'louca', 'sozinha', 'msm', 'dragão', 'sigur_ross_', 'arrasta', 'maxxxramon', 'choque', 'tbt', 'assista', 'crítica', 'arrobanerd', 'longa', 'traz', 'reviravoltas', 'tirar', 'fôlego', 'paulo__junior__', 'ignorou', 'som', 'redor', 'principal', 'resistia', 'exatamente', 'rasteira', 'contraditório', 'nas', 'ideias', 'escreve', 'saber', 'metáfora', 'p', 'gyn', 'tô', 'lembrando', 'cena', 'fala', 'personagens', 'sob', 'efeito', 'forte', 'psicotrópico', 'morrer', 'hauahuahuahuhauauuahuahuauuahuahhuahuauuahuahhuahuauuahuah', 'camisetinha', 'temos', 'so', '1', 'pessoa', 'reclamando', 'alguma', 'boyzinha', 'xuliaxx', 'zap', 'conversar', 'seguinte', 'eupalmeirensa', 'laianexx', 'laiane', 'quer', 'morenamoraes', 'abruxapreta', 'cinemarkoficial', 'querendo', 'salas', 'posso', 'abre', 'nenhuma', 'h4ckaq', 'dor', 'cabeça', 'enjoo', 'vontade', 'ressaca', 'diálogos', 'companhia', 'sincera', 'tomar', 'açaí', 'verdade', 'beber', 'aff', 'sinopse', 'interessou', 'bastante', 'lucasnunnes97', '_msoliveira', 'processando', 'tanta', 'atualmente', 'gastei', 'chance', 'vendo', 'aquela', 'tranqueira', 'incrível', 'adjetivos', 'qualidade', 'deveriam', 'provavelmente', 'ja', 'cinemark', 'então', 'cuiabano', 'prestigiar', 'hein', 'faltava', 'unisse', 'todas', 'tribos', 'pablomoreno', 'amei', 'sertão', 'impacto', 'lucidez', 'realização', 'precisa', 'digerir', 'após', 'muitos', 'elogios', 'espero', 'encante', 'hj', 'assisto', 'refrescos', 'agenda', 'conturbada', 'parça', '♥', 'meio', 'loucura', 'assistido', 'mandei', 'tweet', 'mauromendoncaf', 'engravidar', 'louco', 'tesao', 'sendo', 'socorro', 'dizer', '“amiga', 'juntas”', 'supero', 'aniversario', 'paga', 'única', 'entendi', 'ns', 'this', 'is', 'homofobia', 'filhudi', 'filhusi', 'brasilia', 'w', 'fé', 'poder', 'fernanda', 'reservando', 'são', 'luiz', 'alunos', '🤧', '🥰', '😭', 'óbvio', 'enfiar', 'obra', 'inspira', 'maravilha', 'silveropereira', 'votei', 'assistiria', 'hora', 'penso', 'perplexo', 'recorte', 'irregular', 'obsessões', 'exportação', 'comentar', 'realidade', 'amigas', 'essas', 'histórias', 'itimalian', 'bacurit', 'kkkkk', 'aaa', 'filha', 'pois', 'trate', 'cinem', 'volta', 'agoraaaaaaa', 'viaverdeshop', 'amiguinho', 'queira', 'preferência', 'segunda', 'quarta', 'preço', 'promocional', 'postando', 'plena', 'convicção', 'flop', 'citar', 'correntes', 'além', 'central', 'ela', 'amanhã', 'mesa', 'buteco', 'centro', 'cmggg', 'algm', 'hd5trange', 'nice', 'comprando', 'ingresso', 'naquelas', 'máquinas', 'deu', 'gritar', 'filmão', 'caray', 'onde', 'refletir', 'virá', 'escolas', 'museus', 'sentido', 'literal', 'figurado', 'tentar', 'recuperar', 'projeto', 'entregar', 'rever', 'dressasantiago_', 'diferenciado', 'chamaram', 'estamos', 'evoluindo', 'caionare4l', 'vim', 'humildemente', 'irem', 'assitir', 'perfeitooo', 'iamplanett', 'atenção', '22', '09', 'passar', 'vitória', 'opção', 'barata', 'local…', 'bacuraufilme', 'façam', 'teste', 'domingas', 'orgulho', 'objetivos', 'cumpridos', 'beareclama', 'kkkk', 'falta', 'pacote', 'teresa', 'pospunkcearense', 'tabacaria', 'impossível', 'inagaki', 'virar', 'sou', 'via', 'davirocha', 'bluecoloredboy', 'conte', 'amo', 'socorr', 'kkkkkkk', 'tirou', 'própria', 'cidade', 'amigável', 'pacífica', 'tentando', 'atrapalhar', 'sua', 'obrigada', 'próprias', 'rédeas', 'destino', 'continuar', 'sobrevivendo', 'omegamark_xii', 'te', 'agostinho', 'carrara', 'matar', 'carara', 'matemática', 'basica', 'marque', 'ami…', 'ifavmarkten', 'tive', 'pesquisar', 'google', 'vc', 'escrevendo', 'bacalhau', 'heinhein', 'sdds', 'umazinha', 'ficar', 'alterada', 'johnforfans', 'vamo', 'tarde', 'nadar', 'minas', 'dps', 'f1', 'comer', 'sorvete', 'conversando', 'yearofsilencce', 'mia', 'links', 'favoooorre', 'c0breira', 'easter', 'eggs', 'cobreiros', 'papai', 'responsável', 'daquele', 'buraco', 'cia', 'cavaram', 'o…', 'ogrunhido', 'confundo', 'batoré', 'personalidade', 'missão', 'nesta', 'capaz', 'cima', 'cumprir', 'seus', 'seja', 'quais', 'forem', 'arrasa', 'visual', 'aplique', 'achando', 'ótimo', 'ouvi', 'uns', '“nossa', 'agora“', 'te…', 'contemplada', 'caravana', 'caiu', 'lágrima', 'gulagcanavieiro', 'pontua', 'acuradamente', 'infelizmente', 'sudeste', 'merda', 'ps', 'yuribt', 'camisa', 'parmera', '2a', 'compartilhe', 'grande', 'abraço', '⚡', '🤯', '🛸', '🍷', 'capa', 'edição', 'cahiers', 'du', 'cinéma', 'revista', 'importante', 'traz…', 'refletindo', 'cakespacek', 'vá', 'wiiz', 'pedrinhofonseca', 'primeiro', 'fim', 'r', '5mi', 'arrecadados', 'durante', 'gravações', '800', 'empregos', 'gerados', 'lendário', 'uuuuu', 'fluí', 'bacanal', 'perfeita', 'b_soviet', 'abrutaflor', 'piranha', 'galinha', 'tidal', 'épico', 'greggui_', 'penúltimo', 'lista', 'produção', 'franco', 'venceu', 'júri', 'cannes', 'tornand…', 'ah', 'justo', 'claro', 'mtvbrasil', 'arrecada', '5', 'milhão', 'bilheteria', 'final', 'gt', 'voz', 'conhecimento', 'razão', 'consulta', 'importa', 'verdadeira', 'inspiração', 'banhadaaouro', 'busão', 'madrugada', 'issoeomuso', 'resposta', 'moreirapaty', 'inveja', 'caso', 'inclui', 'também', 'hahahahah', 'digno', 'choca', 'rondelicia', 'finja', 'aturar', 'viado', 'enaltecendo', 'riverdale', 'enaltecer', 'gepeto666', 'p_dromenezes', 'somos', 'região', 'tecnologicamente', 'avançada', 'buscando', 'disputar', 'posições', 'regiões', 'clássico', 'xenófobo', 'acham', 'diferenciada', 'paulista', 'carioca', 'testes_damassa', 'fiquei', 'vingadores', 'aviso', 'virmos', 'po…', 'babi', 'colen', '👏🏼', '💗', '“você', '”', 'ma', 'bosta', 'testinhos', 'buzzfeed', '💁🏻', 'vê', 'n4rja', 'palavra', 'entender', 'exemplo', 'bêbada', 'ide…', 'm_i_n_u_s', 'acabei', 'tweets', 'aleatorios', 'sudestino', 'ate', 'bahia', 'nordeste', 'desmerecer', 'uahauahaha', 'axzgazzoni', 'num', 'aqueles', 'ônibus', 'presentear', 'sweet', 'coffee', 'week', 'próxima', 'banco', 'camilamotad', 'sonia', 'braga', 'comprei', 'porta', 'crise', 'ansiedade', 'embora', 'chorando', 'caminho', 'td', 'partir', 'quinta', 'feira', 'sesc', 'rua', 'augusta', 'sp', 'projetado', '4k', 'sonzão', '30…', 'fiz', '😂', 'questão', 'invasões', 'dominações', 'violência', 'parte', 'construiu', 'invadiu', 'população', 'morava', 'dizimada', 'nome', 'civilização', 'pesquisa', 'rápida', 'caralhoooo', 'cancelada', 'cadê', 'chega', 'chernobabe', '“po', 'assiste', 'bacurau”', 'olhe', 'peh', 'usando', 'sandalia', 'couro', 'midianinja', '“bacurau”', 'ilustra', '“cahiers', 'cinéma”', 'conceituada', 'francesa', 'conh…', 'vetromn', 'cidades', 'dnlnblgng', 'menos', 'respeito', 'gíria', 'sexual', 'boto', 'pezinhos', 'fora', 'carlos', 'começam', 'exibir', 'boazinha', 'esperar', 'ccamls', 'sobrevivend9', 'esperança', 'isura_eru', 'fanart', 'mikhaetc', 'conquistas', 'juri', 'jovem', 'transar', 'querer', 'assassinar', 'gringo', 'filadaputa', 'ldna', 'tinha', 'hahaha', 'impressionada', 'in…', 'mostra', 'derrotar', 'ataques', 'bolsonários', 'conversaafiada', 'inteira', 'carapuça', 'serviu', 'dontcallmealf', 'acredito', 'piracicaba', 'enquanto', 'falacioso', 'segue', '2…', 'tjxciv', '24h', 'chamei', 'tia', 'combinamos', 'chegamos', 'descobrimos', 'virou', 'programação', 'resultado', 'passado', 'condena', 'netrlix', 'jdornelles', 'oficial', 'disponível', 'spotify', 'deezer', 'apple', 'music', 'play', '🎻', '🎺', '🥁', '🎼', '_', 'náusea', 'pulo_', 'beijar', 'dormir', 'acordar', 'feirinha', 'pq10', 'senhor', 'sondas', '🤩', '😍', 'putz', 'diria', 'candymel', '🎵', 'completa', 'escutar', 'fi…', 'izarcosta', 'fosse', 'acionar', 'meme', 'juliancampos', 'café', 'recebi', 'sachê', 'açúcar', 'entra', '200', '💥', 'deixe', 'f…', 'heisenboff', 'ultima', 'brasileira', 'este', 'nervosa', '~~bacurau', 'mirror~~', 'conseguindo', 'cineart', 'boulos', 'chegando', 'metrópolis', 'coincidência', 'segundo', 'votos', 'internacionais', 'cinco', 'década', 'parasita', 'aranha', 'aran…', 'tehpipimi', 'irmao', 'desde', '2014', 'reclama…', 'j0anacs', 'high', 'life', 'shecomesincolo1', 'ícone', 'berrando', 'perguntas', 'bacurauverso', 'acabou', 'trailer', 'tv', 'lotérica', 'desses', 'reforma', 'previdência', 'algo', 'comassim', 'justíssimo', 'mano', 'dessa', 'voltar', 'unha', 'homenagear', 'femesmo', 'bastou', 'forçar', 'associação', 'absolutamente', 'kkkkkkkkkkkkkkkkkkkkkkkkk', 'alveskath', 'certo', '😁', 'medo', 'levantar', 'água', 'cozinha', 'alicepa', 'imagina', 'branco', 'americano', 'diferente', 'torrents', '[eu', 'mesma', 'bibliotecária', 'referência]', 'bacurinho', 'dei', 'boas', 'risadas', 'parabens', '👍', 'kdstephanie', 'últimos', 'sabendo', 'lidar', 'badgesucks', 'enxergarmos', 'prisma', 'sociedade', 'vivemos', 'iremos', 'compreender', 'proposta', '_o_gugga', 'igual', 'overdose', 'emocomrade', 'intenso', 'vitrine_filmes', 'mail', 'show', 'macaé', 'pedi', 'passarem', '😟', 'jazzbfr', 'quase', 'nunca', 'custa', 'meia', 'obriga', 'presença', 'ela…', 'né', 'isentão', 'espécie', 'tropa', 'elite', 'esquerda', 'uso', 'catártica…', 'playlist', 'virginiaamoon', 'época', 'araputanga', 'apelido', 'super', 'engraçado', 'co', 'descobrir', 'hahahahahahahahaha', 'taurina', 'próprio', '10', 'crime', 'camaradas', 'fan', 'merchand', 'ator', 'prefeito', 'tony', 'júnior', 'curtiu', 'comentou', 'desenho', 'feliz', 'dms', 'rmovinup', 'amoooooo', 'euzinha', '♡', 'diariope', 'mata', 'tudinho', 'faca', 'oficialmente', 'botei', 'foder', 'rainha', 'teco', 'bebês', 'zadorarocha', 'comprar', 'guarda', 'chuva', 'ielison_', 'alô', 'campina', 'horários', '15', '35', 'pamonha', 'curau', 'dou', 'passarinho', 'ddaenerys', '“assiste', 'pagar', 'limpar', 'disso', 'xenofobico', 'peço', 'ruimdrigo_', 'rima', 'cosmopolita', 'conquistando', 'jamais', 'esquece', 'suas', 'raízes', 'perde', 'ligação', 'srra', 'esforço', 'dificuldade', 'cidadão', 'andreense', 'horário', '22h30', 'carro', 'quê', 'pobre', 'negócio', 'saiu', 'raivaaa', 'aquele', 'f', 'gregoriorrr', 'sulista', 'bola', 'tira', 'belissimo', 'sarro', 'sulist…', 'delicia', 'ó', 'capitalismo', 'matastes', 'grito', 'povoado', 'chegaram', 'masterclass', 'editor', 'facha', 'critiquei', 'esta', 'aaaaaaaaaaaa', 'parar', 'i', 'got', 'silvero', 'pereira', 'yanplm123', 'men', 'teu', 'insta', 'melted', 'vídeos', 'buzzfeedbrasil', 'quiz', 'honra', 'meupai', 'pega', 'come', 'paulomoreria', 'ciladapieper', 'anigos', 'paiaçada', 'ahahahah', 'pior', 'concordo', 'resumo', 'vibes', 'vomite', 'saio', 'atirando', 'mesmooooo', 'vir', 'evildebora', 'evildani13', 'cansadae', 'juliexndrews', 'ódio', 'pantanal', 'passada', 'tinha…', 'tatifers', 'papocultura', 'história', 'cobra', 'colunista', 'sihan', 'felix', 'blog', 'papo', 'à', 'torna', 'gosta', 'asas', 'longe', 'pássaro', 'território', 'acaba', 'voltando', 'fiel', 'coragem', 'trouxa', 'inventa', 'encher', 'move', 'mundos', 'fundos', 'defender', 'entes', 'queridos', 'certíssimo', 'conta', 'detalhe', 'receberá', 'dm', 'mandando', 'shipneide', 'mista', 'vanity', 'fair', 'excessivamente', 'estereotipados', 'pegou', 'shade', 'nan', '3hoje', 'é…bora', 'passasaindo', 'perfeitopoxa', 'bacuraurt', 'aaaaaame', 'bacuraumas', 'tarantinort', 'bacurauserá', 'bacurauacho', 'novoalguém', 'verthread', 'premiaç…era', 'bacurauquero', 'bacuraucaralhoo', 'bacuraunamoral', 'pqpgente', 'caralhobacurau', 'dáeu', 'bichobacurau', 'vãomeu', 'semanart', 'deusna', 'verminha', 'delesit', 'alheiabacurau', '9alguem', 'caraitoda', 'bacurauvsffffffff', 'bacuraugente', 'feitort', 'sobre…quero', 'bacurauainda', 'nacionalacho', 'aindasexo', 'msmalguém', 'favorrt', 'gyntô', 'hauahuahuahuhauauuahuahuauuahuahhuahuauuahuahhuahuauuahuahcamisetinha', 'nenhumart', 'umaqueria', 'affa', 'filmaçoquero', 'bacurautanta', 'cinemahoje', 'heinaté', 'conturbadabacurau', 'pqpe', 'deusninguém', 'superogalera', 'bacurauninguém', 'deusns', 'wtenho', 'bacuraueu', 'maisfernanda', 'istotoda', 'perplexocrítica', 'amigasmt', 'cuminha', 'viaverdeshopalgum', 'bacurausó', 'cmgggtudo', 'nicetá', 'novovi', 'coisapreciso', 'simbacurau', 'filhon', 'bacurauqual', 'paísrt', 'brasi…por', 'oposiçãort', 'bacurauprofessora', 'amigatendo', 'sanguevcs', '…o', 'istort', 'local…rt', 'paztirei', 'mimtodos', 'kkkksó', 'davirochatirei', 'ami…rt', 'conversandotirei', 'o…que', 'te…muito', 'merdakkkkkkk', 'traz…tirei', 'brasi…rt', 'ami…tirei', 'galinhatirei', 'tornand…você', 'com…rt', 'bacuraujusto', 'hahahahahachei', 'sime', 'po…rt', 'traz…eu', 'te…kkkkkk', 'ide…rt', 'é…rt', 'te…rt', 'ontemrt', '30…2', 'galinhagente', 'courort', 'conh…tirei', 'bacurauvocê', 'sexualrt', 'te…meu', 'faculdadert', 'filadaputaonde', 'hojert', 'in…bacurau', 'conversaafiadatirei', '2…rt', 'bacurauchamei', 'netrlixtirei', 'ide…_', 'bacurautirei', 'sondasé', 'bacuraua', 'brasi…quem', 'courotirei', 'fi…eu', 'f…rt', 'destinoeu', 'mirror~~menina', 'traz…alguém', 'aran…rt', 'reclama…rt', 'fi…rt', 'nacionalrt', 'falamtirei', 'bacurauversoporra', 'o…kkkkkkkkkkkkkkkkkkkkkkkkk', 'te…pensar', 'bacurinhacomo', 'destinová', 'kkkkkkkkrt', '…mas', 'intensofiz', 'in…rt', 'simrt', 'ela…nao', 'catártica…carai', 'perfeitao', 'nomemedo', 'davirochart', 'brasi…tirei', 'bacurauquem', 'carlostirei', 'affcomprar', 'comigort', '…pamonha', 'bacuraumais', 'passarinhort', 'entãort', 'fi…ontem', 'rimaqual', 'ela…a', 'culturalrt', 'com…eu', 'raivaaabacurau', 'peixert', 'frt', 'sulist…tirei', 'courocaralho', 'faculdadeaaaaaaaaaaaa', 'kkkkkkkamei', 'fi…tirei', 'meupaibacurau', 'comert', 'entãotirei', 'anigosporra', 'doidort', 'te…tirei', 'cansadaert', 'tinha…qual', 'chuvart', 'curt', 'o…a']\n"
     ]
    }
   ],
   "source": [
    "palavras_totais = [] #lista com todas as palavras sem duplicatas\n",
    "\n",
    "for palavra in lista_relativa:\n",
    "    if palavra not in palavras_totais:\n",
    "        palavras_totais.append(palavra)\n",
    "for palavra in lista_relevante:\n",
    "    if palavra not in palavras_totais:\n",
    "        palavras_totais.append(palavra)\n",
    "for palavra in lista_irrelevante:\n",
    "    if palavra not in palavras_totais:\n",
    "        palavras_totais.append(palavra)    \n",
    "print(palavras_totais)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_irr={}\n",
    "freq_rel={}\n",
    "\n",
    "for palavra in palavras_totais:\n",
    "    freq_irr[palavra]=1\n",
    "    freq_rel[palavra]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nossa': 3,\n",
       " 'eu': 28,\n",
       " 'desviei': 1,\n",
       " 'muito': 6,\n",
       " 'rápido': 1,\n",
       " 'de': 75,\n",
       " 'um': 17,\n",
       " 'spoiler': 2,\n",
       " 'bacurau': 130,\n",
       " 'me': 15,\n",
       " 'senti': 1,\n",
       " 'ninja': 1,\n",
       " 'rt': 6,\n",
       " 'avokdoido': 2,\n",
       " 'quem': 8,\n",
       " 'nao': 5,\n",
       " 'gostou': 2,\n",
       " 'é': 29,\n",
       " 'no': 24,\n",
       " 'mínimo': 3,\n",
       " 'do': 29,\n",
       " 'pouco': 2,\n",
       " 'nazista': 2,\n",
       " 'sim': 5,\n",
       " 'vi': 5,\n",
       " 'ontem': 6,\n",
       " 'com': 16,\n",
       " 'a': 37,\n",
       " 'viviane_cardoso': 2,\n",
       " 'o': 42,\n",
       " 'filme': 30,\n",
       " 'fantástico': 2,\n",
       " 'vale': 2,\n",
       " 'pena': 3,\n",
       " 'ver': 40,\n",
       " 'se': 6,\n",
       " 'você': 7,\n",
       " 'tiver': 2,\n",
       " 'mente': 2,\n",
       " 'aberta': 2,\n",
       " 'e': 53,\n",
       " 'qualquer': 3,\n",
       " 'coisa': 8,\n",
       " 'que': 60,\n",
       " 'faço': 2,\n",
       " 'vivi': 2,\n",
       " 'sempre': 3,\n",
       " 'bom': 12,\n",
       " 'companheira': 2,\n",
       " 'filmes': 7,\n",
       " 'vida': 4,\n",
       " 'lutas': 2,\n",
       " 'lt': 2,\n",
       " '3': 1,\n",
       " 'hoje': 8,\n",
       " 'finalmente': 3,\n",
       " 'vejo': 2,\n",
       " 'será': 2,\n",
       " 'consigo': 2,\n",
       " 'chegar': 2,\n",
       " 'até': 4,\n",
       " 'sala': 3,\n",
       " 'livre': 2,\n",
       " 'tá': 9,\n",
       " 'difícil': 2,\n",
       " 'lzanin': 2,\n",
       " 'texto': 2,\n",
       " 'marcelo': 2,\n",
       " 'coelho': 2,\n",
       " 'chama': 2,\n",
       " '‘bolsonarisno': 2,\n",
       " 'sinal': 2,\n",
       " 'trocado’': 2,\n",
       " 'lembra': 2,\n",
       " 'ideia': 2,\n",
       " 'alguns': 2,\n",
       " 'jornalistas': 2,\n",
       " 'na': 8,\n",
       " 'é…': 1,\n",
       " 'diretor': 1,\n",
       " 'joão': 1,\n",
       " 'kleber': 1,\n",
       " 'mendonça': 2,\n",
       " 'filho': 2,\n",
       " 'n': 2,\n",
       " 'vou': 12,\n",
       " 'conseguir': 1,\n",
       " 'qual': 1,\n",
       " 'desse': 4,\n",
       " 'q': 11,\n",
       " 'galera': 2,\n",
       " 'ta': 5,\n",
       " 'doida': 2,\n",
       " 'achei': 2,\n",
       " 'era': 6,\n",
       " 'peixe': 1,\n",
       " 'isso': 3,\n",
       " 'vai': 11,\n",
       " 'assistir': 32,\n",
       " 'sai': 1,\n",
       " 'maluco': 1,\n",
       " 'todo': 4,\n",
       " 'dia': 4,\n",
       " 'bora': 2,\n",
       " 'galeres': 2,\n",
       " 'aproveitando': 1,\n",
       " 'pra': 41,\n",
       " 'divulgar': 2,\n",
       " 'melhor': 8,\n",
       " '2019': 2,\n",
       " 'personagem': 3,\n",
       " 'tirei': 2,\n",
       " 'lunga': 2,\n",
       " 'aí': 4,\n",
       " 'cara': 1,\n",
       " 'já': 9,\n",
       " 'assistiu': 2,\n",
       " '𝐉𝐚́': 1,\n",
       " '𝐚𝐬𝐬𝐢𝐬𝐭𝐢𝐮': 1,\n",
       " '𝐁𝐚𝐜𝐮𝐫𝐚𝐮': 1,\n",
       " 'jά': 1,\n",
       " 'αssιsτιυ': 1,\n",
       " 'βαcυrαυ': 1,\n",
       " '𝕵𝖆́': 1,\n",
       " '𝖆𝖘𝖘𝖎𝖘𝖙𝖎𝖚': 1,\n",
       " '𝕭𝖆𝖈𝖚𝖗𝖆𝖚': 1,\n",
       " 'jᴀ́': 1,\n",
       " 'ᴀssɪsᴛɪᴜ': 1,\n",
       " 'bᴀᴄᴜʀᴀᴜ﹖': 1,\n",
       " 'foda': 4,\n",
       " 'omelete': 2,\n",
       " 'ainda': 9,\n",
       " 'foi': 6,\n",
       " 'visto': 2,\n",
       " 'por': 7,\n",
       " 'mais': 15,\n",
       " '130': 1,\n",
       " 'mil': 1,\n",
       " 'pessoas': 1,\n",
       " 'diariosm': 2,\n",
       " 'sucesso': 2,\n",
       " 'público': 2,\n",
       " 'não': 21,\n",
       " 'deve': 3,\n",
       " 'ser': 5,\n",
       " 'exibido': 2,\n",
       " 'nos': 5,\n",
       " 'cinemas': 3,\n",
       " 'santa': 2,\n",
       " 'maria': 2,\n",
       " 'aparentemente': 1,\n",
       " 'só': 9,\n",
       " 'ao': 5,\n",
       " 'nesse': 1,\n",
       " 'país': 3,\n",
       " 'sábado': 2,\n",
       " 'to': 8,\n",
       " 'ansiosíssimaaaa': 2,\n",
       " 'fds': 2,\n",
       " 'passa': 1,\n",
       " 'saindo': 1,\n",
       " 'cedo': 2,\n",
       " 'da': 11,\n",
       " 'faculdade': 4,\n",
       " 'correndo': 2,\n",
       " 'kmendoncafilho': 6,\n",
       " 'cine': 2,\n",
       " 'arte': 2,\n",
       " 'uff': 1,\n",
       " 'uma': 12,\n",
       " 'equipada': 1,\n",
       " 'como': 7,\n",
       " 'poucas': 1,\n",
       " 'numa': 2,\n",
       " 'universidade': 1,\n",
       " 'pública': 1,\n",
       " 'lotada': 1,\n",
       " 'estudantes': 1,\n",
       " 'para': 6,\n",
       " 'brasi…': 1,\n",
       " 'fazendo': 2,\n",
       " 'propaganda': 2,\n",
       " 'grandao': 2,\n",
       " 'pro': 3,\n",
       " 'uber': 2,\n",
       " 'aqui': 3,\n",
       " 'ele': 3,\n",
       " 'disse': 4,\n",
       " 'domingo': 2,\n",
       " 'perfeito': 1,\n",
       " 'poxa': 1,\n",
       " 'alguém': 10,\n",
       " 'leva': 5,\n",
       " 'psousadealmeida': 2,\n",
       " 'tenho': 2,\n",
       " 'novo': 8,\n",
       " 'tarantino': 4,\n",
       " 'it': 5,\n",
       " 'aaaaaa': 1,\n",
       " 'favor': 2,\n",
       " 'parem': 1,\n",
       " 'falar': 6,\n",
       " 'às': 2,\n",
       " '20': 3,\n",
       " '40': 1,\n",
       " 'chamem': 2,\n",
       " 'sabe': 2,\n",
       " 'bacurinha': 2,\n",
       " 'thalitamari': 1,\n",
       " '_meirabeatriz': 1,\n",
       " 'menina': 1,\n",
       " 'agora': 5,\n",
       " 'tu': 2,\n",
       " 'tava': 4,\n",
       " 'falando': 4,\n",
       " 'kkkkkk': 2,\n",
       " 'apois': 1,\n",
       " 'gente': 8,\n",
       " 'faz': 3,\n",
       " 'nem': 4,\n",
       " 'treinamento': 1,\n",
       " 'pq': 6,\n",
       " 'esse': 9,\n",
       " 'teria': 1,\n",
       " 'oposição': 1,\n",
       " 'queria': 6,\n",
       " 'ter': 6,\n",
       " 'dinheiro': 3,\n",
       " 'wwwmlna': 5,\n",
       " 'algum': 1,\n",
       " 'homem': 1,\n",
       " 'feminista': 1,\n",
       " 'online': 1,\n",
       " 'disposto': 1,\n",
       " 'dar': 1,\n",
       " 'professora': 1,\n",
       " 'didatica': 1,\n",
       " 'perguntando': 1,\n",
       " 'turma': 1,\n",
       " 'viu': 3,\n",
       " 'mas': 16,\n",
       " 'vocês': 3,\n",
       " 'foram': 3,\n",
       " 'gostei': 2,\n",
       " 'tiduraes': 2,\n",
       " 'em': 17,\n",
       " '31°': 2,\n",
       " 'top': 2,\n",
       " '250': 2,\n",
       " 'letterboxd': 2,\n",
       " 'lindo': 4,\n",
       " 'comigo': 8,\n",
       " 'anarcofino': 1,\n",
       " 'minha': 6,\n",
       " 'ex': 1,\n",
       " 'cineasta': 1,\n",
       " 'cheia': 2,\n",
       " 'dos': 3,\n",
       " 'contatos': 1,\n",
       " 'manda': 1,\n",
       " 'mensagem': 1,\n",
       " 'digo': 1,\n",
       " 'com…': 1,\n",
       " 'hortawitch': 2,\n",
       " 'assistindo': 2,\n",
       " 'estou': 4,\n",
       " 'vivendo': 2,\n",
       " 'ou': 2,\n",
       " 'apenas': 4,\n",
       " 'curtindo': 2,\n",
       " 'retwittando': 2,\n",
       " 'repostando': 2,\n",
       " 'coisas': 2,\n",
       " 'sobre': 12,\n",
       " 'baruchinha': 2,\n",
       " 'tem': 13,\n",
       " 'acho': 5,\n",
       " 'amiga': 3,\n",
       " 'pfvr': 2,\n",
       " '2': 5,\n",
       " 'pode': 2,\n",
       " 'ganhar': 2,\n",
       " 'prêmio': 2,\n",
       " 'ano': 3,\n",
       " 'beijos': 2,\n",
       " 'sabia': 3,\n",
       " 'karine': 2,\n",
       " 'teles': 2,\n",
       " 'dona': 2,\n",
       " 'meu': 8,\n",
       " 'c': 2,\n",
       " 'susto': 2,\n",
       " 'thread': 1,\n",
       " 'deliciosa': 2,\n",
       " 'tesão': 2,\n",
       " 'estreia': 2,\n",
       " '10de10': 2,\n",
       " 'caazalberto': 2,\n",
       " 'escreveu': 2,\n",
       " 'momento': 2,\n",
       " 'boca': 2,\n",
       " 'garotada': 2,\n",
       " 'incomodando': 2,\n",
       " 'gado': 2,\n",
       " '🔥': 2,\n",
       " '🐂': 2,\n",
       " 'review': 2,\n",
       " 'completo': 2,\n",
       " 'site': 2,\n",
       " '👉': 2,\n",
       " 'affandre': 2,\n",
       " 'tanto': 5,\n",
       " 'invisível': 2,\n",
       " 'serão': 2,\n",
       " 'exibidos': 2,\n",
       " 'festival': 2,\n",
       " 'toronto': 2,\n",
       " 'grandes': 2,\n",
       " 'veículos': 2,\n",
       " 'temporada': 2,\n",
       " 'premiaç…': 1,\n",
       " 'aconteceu': 3,\n",
       " 'tudo': 6,\n",
       " 'ruim': 3,\n",
       " 'clap': 4,\n",
       " 'existem': 2,\n",
       " 'imperdíveis': 2,\n",
       " 'pela': 2,\n",
       " 'relevância': 2,\n",
       " 'temática': 2,\n",
       " 'admiráveis': 2,\n",
       " 'pelo': 6,\n",
       " 'significado': 2,\n",
       " 'cultural': 2,\n",
       " 'memoráveis': 2,\n",
       " 'serem': 2,\n",
       " 'emblemáticos': 2,\n",
       " 'tendo': 1,\n",
       " 'monitoria': 1,\n",
       " 'exposição': 1,\n",
       " 'gringos': 2,\n",
       " 'depois': 3,\n",
       " 'matei': 1,\n",
       " 'todos': 2,\n",
       " 'sujei': 1,\n",
       " 'os': 8,\n",
       " 'quadros': 1,\n",
       " 'sangue': 1,\n",
       " 'tempos': 2,\n",
       " 'sombrios': 2,\n",
       " 'apreciar': 2,\n",
       " 'boa': 3,\n",
       " 'resistência': 3,\n",
       " '07': 2,\n",
       " 'setembro': 2,\n",
       " 'poços': 2,\n",
       " 'caldas': 2,\n",
       " 'estarei': 2,\n",
       " 'lá': 3,\n",
       " 'ingressos': 2,\n",
       " 'comprados': 2,\n",
       " 'quero': 8,\n",
       " 'mto': 2,\n",
       " 'ir': 5,\n",
       " 'caralhoo': 1,\n",
       " 'preciso': 6,\n",
       " 've': 2,\n",
       " 'namoral': 1,\n",
       " 'assistam': 3,\n",
       " 'pqp': 1,\n",
       " 'temia': 2,\n",
       " 'veio': 3,\n",
       " 'cinéfilo': 2,\n",
       " 'perto': 2,\n",
       " 'mim': 3,\n",
       " 'tão': 6,\n",
       " 'more': 2,\n",
       " 'bater': 2,\n",
       " 'palma': 2,\n",
       " 'tailandês': 2,\n",
       " 'for': 2,\n",
       " 'va': 2,\n",
       " 'paz': 2,\n",
       " 'casa': 3,\n",
       " 'caralho': 1,\n",
       " 'fica': 4,\n",
       " 'começa': 2,\n",
       " 'pensar': 2,\n",
       " 'cinema': 16,\n",
       " 'cada': 2,\n",
       " 'pensada': 2,\n",
       " 'dá': 1,\n",
       " 'baixar': 2,\n",
       " 'minhas': 3,\n",
       " 'expectativas': 2,\n",
       " 'porque': 2,\n",
       " 'gosto': 2,\n",
       " 'expectativa': 2,\n",
       " 'alta': 2,\n",
       " 'assim': 4,\n",
       " 'ajuda': 2,\n",
       " 'tempo': 6,\n",
       " 'louvando': 2,\n",
       " 'vcs': 2,\n",
       " 'ficam': 2,\n",
       " 'ai': 3,\n",
       " 'oxewill94': 1,\n",
       " 'vez': 2,\n",
       " 'bicho': 1,\n",
       " 'avengers': 2,\n",
       " 'adoro': 2,\n",
       " 'consumo': 2,\n",
       " 'brasileiro': 6,\n",
       " 'saco': 3,\n",
       " 'cheio': 3,\n",
       " 'pararem': 2,\n",
       " 'fico': 3,\n",
       " 'quando': 4,\n",
       " 'falam': 2,\n",
       " 'insistentemente': 2,\n",
       " 'outra': 2,\n",
       " 'diegoquaglia2': 1,\n",
       " 'sei': 3,\n",
       " 'odeio': 1,\n",
       " 'black': 2,\n",
       " 'mirror': 2,\n",
       " 'comparação': 1,\n",
       " '…': 1,\n",
       " 'constrangedor': 1,\n",
       " 'existir': 1,\n",
       " 'instagram': 2,\n",
       " 'chamado': 1,\n",
       " 'bacurau_memes': 1,\n",
       " 'deus': 4,\n",
       " 'faça': 2,\n",
       " 'cair': 2,\n",
       " 'tempi': 2,\n",
       " 'ain': 2,\n",
       " 'aguento': 4,\n",
       " 'ouvir': 3,\n",
       " 'esses': 2,\n",
       " 'porra': 2,\n",
       " 'entulhando': 2,\n",
       " 'timeline': 3,\n",
       " 'herói': 2,\n",
       " 'hollywood': 2,\n",
       " 'ok': 2,\n",
       " 'falo': 3,\n",
       " 'nada': 3,\n",
       " 'deixa': 3,\n",
       " 'exaltar': 2,\n",
       " 'daqui': 2,\n",
       " 'pouquinho': 2,\n",
       " 'tb': 3,\n",
       " 'fazer': 3,\n",
       " 'meus': 2,\n",
       " 'amigos': 2,\n",
       " 'assistirem': 3,\n",
       " 'vão': 2,\n",
       " 'vamos': 5,\n",
       " 'la': 3,\n",
       " 'mudar': 3,\n",
       " 'pais': 2,\n",
       " 'eh': 4,\n",
       " 'possivel': 2,\n",
       " 'eles': 2,\n",
       " 'tenham': 2,\n",
       " 'realmente': 2,\n",
       " 'tirado': 2,\n",
       " 'edir': 2,\n",
       " 'macedo': 2,\n",
       " 'passando': 3,\n",
       " '50': 2,\n",
       " 'semana': 8,\n",
       " 'dias_ligia': 2,\n",
       " 'ninguém': 4,\n",
       " 'perguntou': 4,\n",
       " 'ameei': 2,\n",
       " 'amor': 3,\n",
       " 'bolha': 2,\n",
       " 'hype': 2,\n",
       " 'está': 3,\n",
       " 'maior': 2,\n",
       " 'cmg': 2,\n",
       " 'sido': 2,\n",
       " 'lana': 2,\n",
       " 'del': 2,\n",
       " 'rey': 2,\n",
       " 'harry': 2,\n",
       " 'styles': 2,\n",
       " 'errado': 2,\n",
       " 'nenhum': 5,\n",
       " 'deles': 1,\n",
       " 'desisti': 1,\n",
       " 'isto': 1,\n",
       " 'capitulo': 2,\n",
       " 'ova': 2,\n",
       " 'apoiar': 3,\n",
       " 'esganado': 2,\n",
       " 'pelos': 2,\n",
       " 'norte': 3,\n",
       " 'americanos': 2,\n",
       " 'kkkkkkkk': 2,\n",
       " 'disseram': 2,\n",
       " 'assisti': 4,\n",
       " 'lo': 3,\n",
       " 'vem': 3,\n",
       " 'entrar': 2,\n",
       " 'internet': 3,\n",
       " 'alheia': 1,\n",
       " 'outro': 2,\n",
       " 'tbm': 4,\n",
       " 'aquarius': 3,\n",
       " 'renatoxavoso': 2,\n",
       " 'kléber': 2,\n",
       " 'entre': 4,\n",
       " 'coma': 2,\n",
       " 'cu': 2,\n",
       " 'toda': 2,\n",
       " 'família': 2,\n",
       " 'obrigado': 2,\n",
       " 'demais': 2,\n",
       " 'inuyalice': 2,\n",
       " 'fui': 3,\n",
       " '99': 3,\n",
       " 'certeza': 2,\n",
       " 'ia': 2,\n",
       " 'sair': 2,\n",
       " 'tiraram': 3,\n",
       " 'yesterday': 3,\n",
       " 'amigo': 3,\n",
       " 'sessão': 6,\n",
       " 'das': 3,\n",
       " '9': 3,\n",
       " 'teve': 2,\n",
       " 'alguem': 4,\n",
       " 'amanha': 2,\n",
       " 'stargirllv': 2,\n",
       " 'carai': 1,\n",
       " 'bê': 2,\n",
       " 'indo': 2,\n",
       " 'yuri_reinaldo': 2,\n",
       " '16': 2,\n",
       " 'horas': 3,\n",
       " 'pensando': 2,\n",
       " 'cinesiageek': 2,\n",
       " 'deveria': 3,\n",
       " 'elogio': 2,\n",
       " 'tipo': 3,\n",
       " 'mó': 2,\n",
       " 'comédia': 2,\n",
       " 'ação': 2,\n",
       " 'drama': 2,\n",
       " 'it2': 4,\n",
       " 'mt': 2,\n",
       " 'ansiosa': 2,\n",
       " 'principalmente': 2,\n",
       " 'as': 5,\n",
       " 'meninas': 2,\n",
       " '🥳': 2,\n",
       " 'aula': 2,\n",
       " 'vsffffffff': 1,\n",
       " 'lugar': 2,\n",
       " 'pros': 2,\n",
       " 'lados': 2,\n",
       " 'zona': 2,\n",
       " 'madureira': 2,\n",
       " 'shopping': 2,\n",
       " 'rei': 2,\n",
       " 'leao': 2,\n",
       " 'programado': 2,\n",
       " 'meier': 2,\n",
       " 'sessao': 2,\n",
       " '21h': 2,\n",
       " 'noite': 4,\n",
       " 'puta': 2,\n",
       " 'excelente': 2,\n",
       " 'saudável': 2,\n",
       " 'catarse': 2,\n",
       " 'aliás': 2,\n",
       " 'mesmo': 4,\n",
       " 'oxigene': 2,\n",
       " 'maoleskine': 2,\n",
       " 'maratonar': 2,\n",
       " 'breve': 2,\n",
       " 'again': 2,\n",
       " 'primeira': 2,\n",
       " 'lançamento': 2,\n",
       " 'determina': 2,\n",
       " 'quanto': 4,\n",
       " 'cartaz': 2,\n",
       " 'essa': 5,\n",
       " 'lançado': 2,\n",
       " 'maravilhoso': 2,\n",
       " 'mundo': 3,\n",
       " 'sério': 3,\n",
       " 'brasileiros': 2,\n",
       " '❤': 2,\n",
       " '️': 3,\n",
       " 'sopranine': 1,\n",
       " 'ali': 3,\n",
       " 'juntas': 2,\n",
       " 'moskito': 2,\n",
       " 'recebendo': 2,\n",
       " 'mandar': 2,\n",
       " 'grupo': 2,\n",
       " 'dividido': 2,\n",
       " 'amou': 2,\n",
       " 'odiou': 2,\n",
       " 'idosas': 2,\n",
       " 'estavam': 2,\n",
       " 'gostaram': 3,\n",
       " 'admitiram': 2,\n",
       " 'bem': 3,\n",
       " 'feito': 1,\n",
       " 'wotzik': 2,\n",
       " 'brasil': 3,\n",
       " 'urgente': 2,\n",
       " 'vivam': 2,\n",
       " 'necessário': 2,\n",
       " 'iskindolele': 2,\n",
       " 'estava': 3,\n",
       " 'obcecado': 3,\n",
       " 'passava': 3,\n",
       " '80': 3,\n",
       " 'outros': 3,\n",
       " 'torcia': 3,\n",
       " 'falasse': 3,\n",
       " 'sobre…': 1,\n",
       " 'porém': 3,\n",
       " 'afirmo': 2,\n",
       " 'tranquilidade': 2,\n",
       " 'milenio': 2,\n",
       " 'veja': 3,\n",
       " 'molena': 2,\n",
       " 'incentive': 2,\n",
       " 'nacional': 4,\n",
       " 'meter': 2,\n",
       " 'doido': 2,\n",
       " 'logo': 2,\n",
       " 'iguatemi': 2,\n",
       " 'antes': 3,\n",
       " 'fique': 2,\n",
       " 'sem': 3,\n",
       " 'minh': 2,\n",
       " 'dando': 2,\n",
       " 'palestra': 2,\n",
       " 'pessoal': 2,\n",
       " 'fez': 2,\n",
       " 'trilha': 2,\n",
       " 'sonora': 2,\n",
       " 'mimos': 2,\n",
       " 'pai': 2,\n",
       " 'aquelacristiana': 2,\n",
       " 'fãs': 3,\n",
       " '=': 3,\n",
       " 'melhores': 3,\n",
       " 'parece': 2,\n",
       " 'infinitamente': 2,\n",
       " 'interessante': 2,\n",
       " 'rodrigoazo': 2,\n",
       " 'olha': 3,\n",
       " 'motivo': 2,\n",
       " 'vermos': 2,\n",
       " 'filmaço': 3,\n",
       " 'ode': 2,\n",
       " 'nosso': 2,\n",
       " 'sobretudo': 2,\n",
       " 'valente': 2,\n",
       " 'povo': 2,\n",
       " 'nordestino': 2,\n",
       " 'sensação': 2,\n",
       " 'reencontro': 2,\n",
       " 'cultura': 2,\n",
       " 'retrato': 2,\n",
       " 'histórico': 2,\n",
       " 'majestoso': 2,\n",
       " 'viva': 2,\n",
       " 'chegou': 2,\n",
       " 'jundiaí': 2,\n",
       " 'sexo': 1,\n",
       " 'sagrado': 2,\n",
       " 'seu': 2,\n",
       " 'corpo': 2,\n",
       " 'templo': 2,\n",
       " 'compartilhá': 2,\n",
       " 'louca': 2,\n",
       " 'sozinha': 2,\n",
       " 'msm': 1,\n",
       " 'dragão': 2,\n",
       " 'sigur_ross_': 2,\n",
       " 'arrasta': 2,\n",
       " 'maxxxramon': 2,\n",
       " 'choque': 2,\n",
       " 'tbt': 2,\n",
       " 'assista': 2,\n",
       " 'crítica': 3,\n",
       " 'arrobanerd': 2,\n",
       " 'longa': 2,\n",
       " 'traz': 2,\n",
       " 'reviravoltas': 2,\n",
       " 'tirar': 2,\n",
       " 'fôlego': 2,\n",
       " 'paulo__junior__': 1,\n",
       " 'ignorou': 2,\n",
       " 'som': 2,\n",
       " 'redor': 2,\n",
       " 'principal': 2,\n",
       " 'resistia': 2,\n",
       " 'exatamente': 2,\n",
       " 'rasteira': 2,\n",
       " 'contraditório': 2,\n",
       " 'nas': 3,\n",
       " 'ideias': 2,\n",
       " 'escreve': 2,\n",
       " 'saber': 2,\n",
       " 'metáfora': 2,\n",
       " 'p': 3,\n",
       " 'gyn': 1,\n",
       " 'tô': 1,\n",
       " 'lembrando': 2,\n",
       " 'cena': 2,\n",
       " 'fala': 2,\n",
       " 'personagens': 2,\n",
       " 'sob': 2,\n",
       " 'efeito': 2,\n",
       " 'forte': 2,\n",
       " 'psicotrópico': 2,\n",
       " 'morrer': 3,\n",
       " 'hauahuahuahuhauauuahuahuauuahuahhuahuauuahuahhuahuauuahuah': 1,\n",
       " 'camisetinha': 1,\n",
       " 'temos': 2,\n",
       " 'so': 3,\n",
       " '1': 2,\n",
       " 'pessoa': 4,\n",
       " 'reclamando': 2,\n",
       " 'alguma': 3,\n",
       " 'boyzinha': 2,\n",
       " 'xuliaxx': 2,\n",
       " 'zap': 2,\n",
       " 'conversar': 2,\n",
       " 'seguinte': 2,\n",
       " 'eupalmeirensa': 2,\n",
       " 'laianexx': 2,\n",
       " 'laiane': 2,\n",
       " 'quer': 2,\n",
       " 'morenamoraes': 2,\n",
       " 'abruxapreta': 2,\n",
       " 'cinemarkoficial': 2,\n",
       " 'querendo': 2,\n",
       " 'salas': 2,\n",
       " 'posso': 2,\n",
       " 'abre': 2,\n",
       " 'nenhuma': 2,\n",
       " 'h4ckaq': 2,\n",
       " 'dor': 2,\n",
       " 'cabeça': 2,\n",
       " 'enjoo': 2,\n",
       " 'vontade': 3,\n",
       " 'ressaca': 2,\n",
       " 'diálogos': 2,\n",
       " 'companhia': 2,\n",
       " 'sincera': 2,\n",
       " 'tomar': 3,\n",
       " 'açaí': 2,\n",
       " 'verdade': 2,\n",
       " 'beber': 2,\n",
       " 'aff': 1,\n",
       " 'sinopse': 2,\n",
       " 'interessou': 2,\n",
       " 'bastante': 2,\n",
       " 'lucasnunnes97': 2,\n",
       " '_msoliveira': 2,\n",
       " 'processando': 2,\n",
       " 'tanta': 1,\n",
       " 'atualmente': 2,\n",
       " 'gastei': 2,\n",
       " 'chance': 2,\n",
       " 'vendo': 2,\n",
       " 'aquela': 2,\n",
       " 'tranqueira': 2,\n",
       " 'incrível': 2,\n",
       " 'adjetivos': 2,\n",
       " 'qualidade': 2,\n",
       " 'deveriam': 2,\n",
       " 'provavelmente': 2,\n",
       " 'ja': 2,\n",
       " 'cinemark': 2,\n",
       " 'então': 2,\n",
       " 'cuiabano': 2,\n",
       " 'prestigiar': 2,\n",
       " 'hein': 1,\n",
       " 'faltava': 2,\n",
       " 'unisse': 2,\n",
       " 'todas': 2,\n",
       " 'tribos': 2,\n",
       " 'pablomoreno': 2,\n",
       " 'amei': 3,\n",
       " 'sertão': 2,\n",
       " 'impacto': 3,\n",
       " 'lucidez': 2,\n",
       " 'realização': 2,\n",
       " 'precisa': 2,\n",
       " 'digerir': 2,\n",
       " 'após': 3,\n",
       " 'muitos': 2,\n",
       " 'elogios': 2,\n",
       " 'espero': 2,\n",
       " 'encante': 2,\n",
       " 'hj': 2,\n",
       " 'assisto': 3,\n",
       " 'refrescos': 2,\n",
       " 'agenda': 2,\n",
       " 'conturbada': 1,\n",
       " 'parça': 2,\n",
       " '♥': 2,\n",
       " 'meio': 3,\n",
       " 'loucura': 2,\n",
       " 'assistido': 2,\n",
       " 'mandei': 2,\n",
       " 'tweet': 2,\n",
       " 'mauromendoncaf': 2,\n",
       " 'engravidar': 3,\n",
       " 'louco': 2,\n",
       " 'tesao': 2,\n",
       " 'sendo': 2,\n",
       " 'socorro': 2,\n",
       " 'dizer': 2,\n",
       " '“amiga': 2,\n",
       " 'juntas”': 2,\n",
       " 'supero': 1,\n",
       " 'aniversario': 2,\n",
       " 'paga': 2,\n",
       " 'única': 2,\n",
       " 'entendi': 2,\n",
       " 'ns': 1,\n",
       " 'this': 2,\n",
       " 'is': 2,\n",
       " 'homofobia': 2,\n",
       " 'filhudi': 2,\n",
       " 'filhusi': 2,\n",
       " 'brasilia': 2,\n",
       " 'w': 1,\n",
       " 'fé': 2,\n",
       " 'poder': 3,\n",
       " 'fernanda': 1,\n",
       " 'reservando': 2,\n",
       " 'são': 2,\n",
       " 'luiz': 2,\n",
       " 'alunos': 2,\n",
       " '🤧': 2,\n",
       " '🥰': 2,\n",
       " '😭': 2,\n",
       " 'óbvio': 2,\n",
       " 'enfiar': 2,\n",
       " 'obra': 2,\n",
       " 'inspira': 2,\n",
       " 'maravilha': 2,\n",
       " 'silveropereira': 2,\n",
       " 'votei': 2,\n",
       " 'assistiria': 2,\n",
       " 'hora': 2,\n",
       " 'penso': 3,\n",
       " 'perplexo': 1,\n",
       " 'recorte': 2,\n",
       " 'irregular': 2,\n",
       " 'obsessões': 2,\n",
       " 'exportação': 2,\n",
       " 'comentar': 3,\n",
       " 'realidade': 2,\n",
       " 'amigas': 1,\n",
       " 'essas': 2,\n",
       " 'histórias': 2,\n",
       " 'itimalian': 1,\n",
       " 'bacurit': 2,\n",
       " 'kkkkk': 2,\n",
       " 'aaa': 2,\n",
       " 'filha': 2,\n",
       " 'pois': 2,\n",
       " 'trate': 2,\n",
       " 'cinem': 2,\n",
       " 'volta': 3,\n",
       " 'agoraaaaaaa': 2,\n",
       " 'viaverdeshop': 1,\n",
       " 'amiguinho': 2,\n",
       " 'queira': 2,\n",
       " 'preferência': 2,\n",
       " 'segunda': 2,\n",
       " 'quarta': 2,\n",
       " 'preço': 2,\n",
       " 'promocional': 2,\n",
       " 'postando': 2,\n",
       " 'plena': 2,\n",
       " 'convicção': 2,\n",
       " 'flop': 2,\n",
       " 'citar': 2,\n",
       " 'correntes': 2,\n",
       " 'além': 2,\n",
       " 'central': 2,\n",
       " 'ela': 2,\n",
       " 'amanhã': 2,\n",
       " 'mesa': 2,\n",
       " 'buteco': 2,\n",
       " 'centro': 2,\n",
       " 'cmggg': 1,\n",
       " 'algm': 2,\n",
       " 'hd5trange': 2,\n",
       " 'nice': 1,\n",
       " 'comprando': 2,\n",
       " 'ingresso': 2,\n",
       " 'naquelas': 2,\n",
       " 'máquinas': 2,\n",
       " 'deu': 2,\n",
       " 'gritar': 2,\n",
       " 'filmão': 2,\n",
       " 'caray': 2,\n",
       " 'onde': 2,\n",
       " 'refletir': 2,\n",
       " 'virá': 2,\n",
       " 'escolas': 2,\n",
       " 'museus': 2,\n",
       " 'sentido': 2,\n",
       " 'literal': 2,\n",
       " 'figurado': 2,\n",
       " 'tentar': 2,\n",
       " 'recuperar': 2,\n",
       " 'projeto': 2,\n",
       " 'entregar': 2,\n",
       " 'rever': 2,\n",
       " 'dressasantiago_': 2,\n",
       " 'diferenciado': 2,\n",
       " 'chamaram': 2,\n",
       " 'estamos': 2,\n",
       " 'evoluindo': 2,\n",
       " 'caionare4l': 2,\n",
       " 'vim': 2,\n",
       " 'humildemente': 2,\n",
       " 'irem': 2,\n",
       " 'assitir': 2,\n",
       " 'perfeitooo': 2,\n",
       " 'iamplanett': 1,\n",
       " 'atenção': 1,\n",
       " '22': 1,\n",
       " '09': 1,\n",
       " 'passar': 1,\n",
       " 'vitória': 1,\n",
       " 'opção': 1,\n",
       " 'barata': 1,\n",
       " 'local…': 1,\n",
       " 'bacuraufilme': 1,\n",
       " 'façam': 1,\n",
       " 'teste': 1,\n",
       " 'domingas': 1,\n",
       " 'orgulho': 1,\n",
       " 'objetivos': 1,\n",
       " 'cumpridos': 1,\n",
       " 'beareclama': 1,\n",
       " 'kkkk': 1,\n",
       " 'falta': 1,\n",
       " 'pacote': 1,\n",
       " 'teresa': 1,\n",
       " 'pospunkcearense': 1,\n",
       " 'tabacaria': 1,\n",
       " 'impossível': 1,\n",
       " 'inagaki': 1,\n",
       " 'virar': 1,\n",
       " 'sou': 1,\n",
       " 'via': 1,\n",
       " 'davirocha': 1,\n",
       " 'bluecoloredboy': 1,\n",
       " 'conte': 1,\n",
       " 'amo': 1,\n",
       " 'socorr': 1,\n",
       " 'kkkkkkk': 1,\n",
       " 'tirou': 1,\n",
       " 'própria': 1,\n",
       " 'cidade': 1,\n",
       " 'amigável': 1,\n",
       " 'pacífica': 1,\n",
       " 'tentando': 1,\n",
       " 'atrapalhar': 1,\n",
       " 'sua': 1,\n",
       " 'obrigada': 1,\n",
       " 'próprias': 1,\n",
       " 'rédeas': 1,\n",
       " 'destino': 1,\n",
       " 'continuar': 1,\n",
       " 'sobrevivendo': 1,\n",
       " 'omegamark_xii': 1,\n",
       " 'te': 1,\n",
       " 'agostinho': 1,\n",
       " 'carrara': 1,\n",
       " 'matar': 1,\n",
       " 'carara': 1,\n",
       " 'matemática': 1,\n",
       " 'basica': 1,\n",
       " 'marque': 1,\n",
       " 'ami…': 1,\n",
       " 'ifavmarkten': 1,\n",
       " 'tive': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for palavra in lista_relevante:\n",
    "    freq_rel[palavra]+=1\n",
    "freq_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nossa': 5,\n",
       " 'eu': 63,\n",
       " 'desviei': 2,\n",
       " 'muito': 17,\n",
       " 'rápido': 2,\n",
       " 'de': 269,\n",
       " 'um': 46,\n",
       " 'spoiler': 5,\n",
       " 'bacurau': 285,\n",
       " 'me': 21,\n",
       " 'senti': 2,\n",
       " 'ninja': 2,\n",
       " 'rt': 17,\n",
       " 'avokdoido': 4,\n",
       " 'quem': 8,\n",
       " 'nao': 9,\n",
       " 'gostou': 5,\n",
       " 'é': 110,\n",
       " 'no': 40,\n",
       " 'mínimo': 7,\n",
       " 'do': 50,\n",
       " 'pouco': 5,\n",
       " 'nazista': 4,\n",
       " 'sim': 5,\n",
       " 'vi': 4,\n",
       " 'ontem': 1,\n",
       " 'com': 38,\n",
       " 'a': 107,\n",
       " 'viviane_cardoso': 1,\n",
       " 'o': 74,\n",
       " 'filme': 28,\n",
       " 'fantástico': 1,\n",
       " 'vale': 2,\n",
       " 'pena': 3,\n",
       " 'ver': 31,\n",
       " 'se': 29,\n",
       " 'você': 75,\n",
       " 'tiver': 1,\n",
       " 'mente': 1,\n",
       " 'aberta': 1,\n",
       " 'e': 107,\n",
       " 'qualquer': 3,\n",
       " 'coisa': 5,\n",
       " 'que': 78,\n",
       " 'faço': 1,\n",
       " 'vivi': 1,\n",
       " 'sempre': 14,\n",
       " 'bom': 5,\n",
       " 'companheira': 5,\n",
       " 'filmes': 2,\n",
       " 'vida': 23,\n",
       " 'lutas': 1,\n",
       " 'lt': 3,\n",
       " '3': 4,\n",
       " 'hoje': 8,\n",
       " 'finalmente': 2,\n",
       " 'vejo': 2,\n",
       " 'será': 1,\n",
       " 'consigo': 2,\n",
       " 'chegar': 1,\n",
       " 'até': 7,\n",
       " 'sala': 13,\n",
       " 'livre': 1,\n",
       " 'tá': 11,\n",
       " 'difícil': 1,\n",
       " 'lzanin': 2,\n",
       " 'texto': 2,\n",
       " 'marcelo': 3,\n",
       " 'coelho': 2,\n",
       " 'chama': 2,\n",
       " '‘bolsonarisno': 2,\n",
       " 'sinal': 2,\n",
       " 'trocado’': 2,\n",
       " 'lembra': 2,\n",
       " 'ideia': 2,\n",
       " 'alguns': 2,\n",
       " 'jornalistas': 2,\n",
       " 'na': 24,\n",
       " 'é…': 1,\n",
       " 'diretor': 4,\n",
       " 'joão': 2,\n",
       " 'kleber': 2,\n",
       " 'mendonça': 3,\n",
       " 'filho': 3,\n",
       " 'n': 8,\n",
       " 'vou': 13,\n",
       " 'conseguir': 2,\n",
       " 'qual': 36,\n",
       " 'desse': 3,\n",
       " 'q': 11,\n",
       " 'galera': 4,\n",
       " 'ta': 5,\n",
       " 'doida': 4,\n",
       " 'achei': 2,\n",
       " 'era': 4,\n",
       " 'peixe': 2,\n",
       " 'isso': 7,\n",
       " 'vai': 10,\n",
       " 'assistir': 31,\n",
       " 'sai': 2,\n",
       " 'maluco': 2,\n",
       " 'todo': 10,\n",
       " 'dia': 5,\n",
       " 'bora': 1,\n",
       " 'galeres': 1,\n",
       " 'aproveitando': 1,\n",
       " 'pra': 30,\n",
       " 'divulgar': 1,\n",
       " 'melhor': 3,\n",
       " '2019': 3,\n",
       " 'personagem': 32,\n",
       " 'tirei': 75,\n",
       " 'lunga': 35,\n",
       " 'aí': 4,\n",
       " 'cara': 3,\n",
       " 'já': 25,\n",
       " 'assistiu': 3,\n",
       " '𝐉𝐚́': 2,\n",
       " '𝐚𝐬𝐬𝐢𝐬𝐭𝐢𝐮': 2,\n",
       " '𝐁𝐚𝐜𝐮𝐫𝐚𝐮': 2,\n",
       " 'jά': 2,\n",
       " 'αssιsτιυ': 2,\n",
       " 'βαcυrαυ': 2,\n",
       " '𝕵𝖆́': 2,\n",
       " '𝖆𝖘𝖘𝖎𝖘𝖙𝖎𝖚': 2,\n",
       " '𝕭𝖆𝖈𝖚𝖗𝖆𝖚': 2,\n",
       " 'jᴀ́': 2,\n",
       " 'ᴀssɪsᴛɪᴜ': 2,\n",
       " 'bᴀᴄᴜʀᴀᴜ﹖': 2,\n",
       " 'foda': 2,\n",
       " 'omelete': 2,\n",
       " 'ainda': 17,\n",
       " 'foi': 8,\n",
       " 'visto': 3,\n",
       " 'por': 17,\n",
       " 'mais': 15,\n",
       " '130': 2,\n",
       " 'mil': 2,\n",
       " 'pessoas': 2,\n",
       " 'diariosm': 1,\n",
       " 'sucesso': 1,\n",
       " 'público': 1,\n",
       " 'não': 34,\n",
       " 'deve': 3,\n",
       " 'ser': 9,\n",
       " 'exibido': 1,\n",
       " 'nos': 8,\n",
       " 'cinemas': 4,\n",
       " 'santa': 1,\n",
       " 'maria': 1,\n",
       " 'aparentemente': 1,\n",
       " 'só': 7,\n",
       " 'ao': 13,\n",
       " 'nesse': 3,\n",
       " 'país': 1,\n",
       " 'sábado': 1,\n",
       " 'to': 6,\n",
       " 'ansiosíssimaaaa': 1,\n",
       " 'fds': 1,\n",
       " 'passa': 5,\n",
       " 'saindo': 1,\n",
       " 'cedo': 2,\n",
       " 'da': 37,\n",
       " 'faculdade': 1,\n",
       " 'correndo': 1,\n",
       " 'kmendoncafilho': 19,\n",
       " 'cine': 17,\n",
       " 'arte': 12,\n",
       " 'uff': 12,\n",
       " 'uma': 42,\n",
       " 'equipada': 12,\n",
       " 'como': 16,\n",
       " 'poucas': 12,\n",
       " 'numa': 13,\n",
       " 'universidade': 12,\n",
       " 'pública': 12,\n",
       " 'lotada': 12,\n",
       " 'estudantes': 12,\n",
       " 'para': 48,\n",
       " 'brasi…': 1,\n",
       " 'fazendo': 2,\n",
       " 'propaganda': 1,\n",
       " 'grandao': 1,\n",
       " 'pro': 1,\n",
       " 'uber': 2,\n",
       " 'aqui': 10,\n",
       " 'ele': 1,\n",
       " 'disse': 3,\n",
       " 'domingo': 1,\n",
       " 'perfeito': 1,\n",
       " 'poxa': 1,\n",
       " 'alguém': 6,\n",
       " 'leva': 2,\n",
       " 'psousadealmeida': 1,\n",
       " 'tenho': 3,\n",
       " 'novo': 15,\n",
       " 'tarantino': 4,\n",
       " 'it': 1,\n",
       " 'aaaaaa': 2,\n",
       " 'favor': 3,\n",
       " 'parem': 4,\n",
       " 'falar': 16,\n",
       " 'às': 4,\n",
       " '20': 5,\n",
       " '40': 2,\n",
       " 'chamem': 1,\n",
       " 'sabe': 10,\n",
       " 'bacurinha': 3,\n",
       " 'thalitamari': 2,\n",
       " '_meirabeatriz': 2,\n",
       " 'menina': 2,\n",
       " 'agora': 8,\n",
       " 'tu': 9,\n",
       " 'tava': 4,\n",
       " 'falando': 6,\n",
       " 'kkkkkk': 2,\n",
       " 'apois': 2,\n",
       " 'gente': 33,\n",
       " 'faz': 4,\n",
       " 'nem': 5,\n",
       " 'treinamento': 2,\n",
       " 'pq': 7,\n",
       " 'esse': 9,\n",
       " 'teria': 2,\n",
       " 'oposição': 1,\n",
       " 'queria': 4,\n",
       " 'ter': 9,\n",
       " 'dinheiro': 7,\n",
       " 'wwwmlna': 6,\n",
       " 'algum': 8,\n",
       " 'homem': 7,\n",
       " 'feminista': 5,\n",
       " 'online': 6,\n",
       " 'disposto': 5,\n",
       " 'dar': 11,\n",
       " 'professora': 1,\n",
       " 'didatica': 2,\n",
       " 'perguntando': 7,\n",
       " 'turma': 4,\n",
       " 'viu': 8,\n",
       " 'mas': 26,\n",
       " 'vocês': 2,\n",
       " 'foram': 3,\n",
       " 'gostei': 1,\n",
       " 'tiduraes': 2,\n",
       " 'em': 32,\n",
       " '31°': 2,\n",
       " 'top': 4,\n",
       " '250': 2,\n",
       " 'letterboxd': 3,\n",
       " 'lindo': 2,\n",
       " 'comigo': 4,\n",
       " 'anarcofino': 5,\n",
       " 'minha': 14,\n",
       " 'ex': 5,\n",
       " 'cineasta': 5,\n",
       " 'cheia': 5,\n",
       " 'dos': 6,\n",
       " 'contatos': 5,\n",
       " 'manda': 5,\n",
       " 'mensagem': 6,\n",
       " 'digo': 6,\n",
       " 'com…': 3,\n",
       " 'hortawitch': 1,\n",
       " 'assistindo': 2,\n",
       " 'estou': 8,\n",
       " 'vivendo': 1,\n",
       " 'ou': 13,\n",
       " 'apenas': 2,\n",
       " 'curtindo': 1,\n",
       " 'retwittando': 1,\n",
       " 'repostando': 1,\n",
       " 'coisas': 2,\n",
       " 'sobre': 9,\n",
       " 'baruchinha': 1,\n",
       " 'tem': 32,\n",
       " 'acho': 3,\n",
       " 'amiga': 3,\n",
       " 'pfvr': 1,\n",
       " '2': 3,\n",
       " 'pode': 5,\n",
       " 'ganhar': 1,\n",
       " 'prêmio': 3,\n",
       " 'ano': 2,\n",
       " 'beijos': 2,\n",
       " 'sabia': 1,\n",
       " 'karine': 1,\n",
       " 'teles': 1,\n",
       " 'dona': 2,\n",
       " 'meu': 17,\n",
       " 'c': 1,\n",
       " 'susto': 1,\n",
       " 'thread': 1,\n",
       " 'deliciosa': 1,\n",
       " 'tesão': 1,\n",
       " 'estreia': 4,\n",
       " '10de10': 5,\n",
       " 'caazalberto': 3,\n",
       " 'escreveu': 3,\n",
       " 'momento': 4,\n",
       " 'boca': 4,\n",
       " 'garotada': 3,\n",
       " 'incomodando': 1,\n",
       " 'gado': 1,\n",
       " '🔥': 1,\n",
       " '🐂': 1,\n",
       " 'review': 2,\n",
       " 'completo': 1,\n",
       " 'site': 1,\n",
       " '👉': 1,\n",
       " 'affandre': 1,\n",
       " 'tanto': 3,\n",
       " 'invisível': 1,\n",
       " 'serão': 1,\n",
       " 'exibidos': 1,\n",
       " 'festival': 2,\n",
       " 'toronto': 1,\n",
       " 'grandes': 1,\n",
       " 'veículos': 1,\n",
       " 'temporada': 1,\n",
       " 'premiaç…': 1,\n",
       " 'aconteceu': 1,\n",
       " 'tudo': 25,\n",
       " 'ruim': 1,\n",
       " 'clap': 1,\n",
       " 'existem': 1,\n",
       " 'imperdíveis': 1,\n",
       " 'pela': 2,\n",
       " 'relevância': 1,\n",
       " 'temática': 1,\n",
       " 'admiráveis': 1,\n",
       " 'pelo': 7,\n",
       " 'significado': 2,\n",
       " 'cultural': 1,\n",
       " 'memoráveis': 1,\n",
       " 'serem': 1,\n",
       " 'emblemáticos': 1,\n",
       " 'tendo': 1,\n",
       " 'monitoria': 2,\n",
       " 'exposição': 2,\n",
       " 'gringos': 2,\n",
       " 'depois': 12,\n",
       " 'matei': 2,\n",
       " 'todos': 12,\n",
       " 'sujei': 2,\n",
       " 'os': 8,\n",
       " 'quadros': 2,\n",
       " 'sangue': 1,\n",
       " 'tempos': 1,\n",
       " 'sombrios': 1,\n",
       " 'apreciar': 1,\n",
       " 'boa': 13,\n",
       " 'resistência': 1,\n",
       " '07': 1,\n",
       " 'setembro': 5,\n",
       " 'poços': 1,\n",
       " 'caldas': 1,\n",
       " 'estarei': 1,\n",
       " 'lá': 3,\n",
       " 'ingressos': 1,\n",
       " 'comprados': 1,\n",
       " 'quero': 4,\n",
       " 'mto': 1,\n",
       " 'ir': 8,\n",
       " 'caralhoo': 1,\n",
       " 'preciso': 1,\n",
       " 've': 1,\n",
       " 'namoral': 1,\n",
       " 'assistam': 2,\n",
       " 'pqp': 1,\n",
       " 'temia': 1,\n",
       " 'veio': 1,\n",
       " 'cinéfilo': 1,\n",
       " 'perto': 1,\n",
       " 'mim': 5,\n",
       " 'tão': 2,\n",
       " 'more': 1,\n",
       " 'bater': 13,\n",
       " 'palma': 1,\n",
       " 'tailandês': 1,\n",
       " 'for': 3,\n",
       " 'va': 2,\n",
       " 'paz': 6,\n",
       " 'casa': 6,\n",
       " 'caralho': 1,\n",
       " 'fica': 1,\n",
       " 'começa': 1,\n",
       " 'pensar': 2,\n",
       " 'cinema': 16,\n",
       " 'cada': 1,\n",
       " 'pensada': 1,\n",
       " 'dá': 1,\n",
       " 'baixar': 1,\n",
       " 'minhas': 1,\n",
       " 'expectativas': 1,\n",
       " 'porque': 2,\n",
       " 'gosto': 1,\n",
       " 'expectativa': 1,\n",
       " 'alta': 2,\n",
       " 'assim': 2,\n",
       " 'ajuda': 4,\n",
       " 'tempo': 2,\n",
       " 'louvando': 1,\n",
       " 'vcs': 3,\n",
       " 'ficam': 2,\n",
       " 'ai': 9,\n",
       " 'oxewill94': 2,\n",
       " 'vez': 1,\n",
       " 'bicho': 1,\n",
       " 'avengers': 1,\n",
       " 'adoro': 1,\n",
       " 'consumo': 1,\n",
       " 'brasileiro': 4,\n",
       " 'saco': 15,\n",
       " 'cheio': 14,\n",
       " 'pararem': 1,\n",
       " 'fico': 2,\n",
       " 'quando': 7,\n",
       " 'falam': 1,\n",
       " 'insistentemente': 1,\n",
       " 'outra': 3,\n",
       " 'diegoquaglia2': 2,\n",
       " 'sei': 8,\n",
       " 'odeio': 3,\n",
       " 'black': 3,\n",
       " 'mirror': 2,\n",
       " 'comparação': 2,\n",
       " '…': 2,\n",
       " 'constrangedor': 2,\n",
       " 'existir': 2,\n",
       " 'instagram': 2,\n",
       " 'chamado': 3,\n",
       " 'bacurau_memes': 2,\n",
       " 'deus': 3,\n",
       " 'faça': 1,\n",
       " 'cair': 1,\n",
       " 'tempi': 1,\n",
       " 'ain': 1,\n",
       " 'aguento': 3,\n",
       " 'ouvir': 3,\n",
       " 'esses': 3,\n",
       " 'porra': 3,\n",
       " 'entulhando': 1,\n",
       " 'timeline': 1,\n",
       " 'herói': 1,\n",
       " 'hollywood': 1,\n",
       " 'ok': 1,\n",
       " 'falo': 1,\n",
       " 'nada': 4,\n",
       " 'deixa': 1,\n",
       " 'exaltar': 1,\n",
       " 'daqui': 3,\n",
       " 'pouquinho': 1,\n",
       " 'tb': 1,\n",
       " 'fazer': 4,\n",
       " 'meus': 2,\n",
       " 'amigos': 1,\n",
       " 'assistirem': 1,\n",
       " 'vão': 3,\n",
       " 'vamos': 3,\n",
       " 'la': 1,\n",
       " 'mudar': 1,\n",
       " 'pais': 1,\n",
       " 'eh': 4,\n",
       " 'possivel': 1,\n",
       " 'eles': 8,\n",
       " 'tenham': 1,\n",
       " 'realmente': 1,\n",
       " 'tirado': 1,\n",
       " 'edir': 2,\n",
       " 'macedo': 1,\n",
       " 'passando': 3,\n",
       " '50': 1,\n",
       " 'semana': 13,\n",
       " 'dias_ligia': 1,\n",
       " 'ninguém': 2,\n",
       " 'perguntou': 1,\n",
       " 'ameei': 1,\n",
       " 'amor': 2,\n",
       " 'bolha': 1,\n",
       " 'hype': 1,\n",
       " 'está': 14,\n",
       " 'maior': 1,\n",
       " 'cmg': 1,\n",
       " 'sido': 1,\n",
       " 'lana': 1,\n",
       " 'del': 1,\n",
       " 'rey': 1,\n",
       " 'harry': 1,\n",
       " 'styles': 1,\n",
       " 'errado': 3,\n",
       " 'nenhum': 1,\n",
       " 'deles': 1,\n",
       " 'desisti': 1,\n",
       " 'isto': 15,\n",
       " 'capitulo': 1,\n",
       " 'ova': 1,\n",
       " 'apoiar': 2,\n",
       " 'esganado': 1,\n",
       " 'pelos': 1,\n",
       " 'norte': 4,\n",
       " 'americanos': 5,\n",
       " 'kkkkkkkk': 2,\n",
       " 'disseram': 1,\n",
       " 'assisti': 6,\n",
       " 'lo': 1,\n",
       " 'vem': 6,\n",
       " 'entrar': 1,\n",
       " 'internet': 1,\n",
       " 'alheia': 1,\n",
       " 'outro': 1,\n",
       " 'tbm': 1,\n",
       " 'aquarius': 1,\n",
       " 'renatoxavoso': 3,\n",
       " 'kléber': 2,\n",
       " 'entre': 3,\n",
       " 'coma': 2,\n",
       " 'cu': 2,\n",
       " 'toda': 4,\n",
       " 'família': 4,\n",
       " 'obrigado': 5,\n",
       " 'demais': 4,\n",
       " 'inuyalice': 1,\n",
       " 'fui': 3,\n",
       " '99': 2,\n",
       " 'certeza': 2,\n",
       " 'ia': 2,\n",
       " 'sair': 4,\n",
       " 'tiraram': 2,\n",
       " 'yesterday': 1,\n",
       " 'amigo': 3,\n",
       " 'sessão': 6,\n",
       " 'das': 5,\n",
       " '9': 2,\n",
       " 'teve': 1,\n",
       " 'alguem': 2,\n",
       " 'amanha': 1,\n",
       " 'stargirllv': 1,\n",
       " 'carai': 3,\n",
       " 'bê': 1,\n",
       " 'indo': 1,\n",
       " 'yuri_reinaldo': 1,\n",
       " '16': 2,\n",
       " 'horas': 3,\n",
       " 'pensando': 2,\n",
       " 'cinesiageek': 1,\n",
       " 'deveria': 15,\n",
       " 'elogio': 1,\n",
       " 'tipo': 2,\n",
       " 'mó': 1,\n",
       " 'comédia': 1,\n",
       " 'ação': 1,\n",
       " 'drama': 2,\n",
       " 'it2': 1,\n",
       " 'mt': 1,\n",
       " 'ansiosa': 1,\n",
       " 'principalmente': 1,\n",
       " 'as': 18,\n",
       " 'meninas': 1,\n",
       " '🥳': 1,\n",
       " 'aula': 2,\n",
       " 'vsffffffff': 1,\n",
       " 'lugar': 1,\n",
       " 'pros': 1,\n",
       " 'lados': 1,\n",
       " 'zona': 1,\n",
       " 'madureira': 1,\n",
       " 'shopping': 1,\n",
       " 'rei': 1,\n",
       " 'leao': 1,\n",
       " 'programado': 1,\n",
       " 'meier': 1,\n",
       " 'sessao': 1,\n",
       " '21h': 1,\n",
       " 'noite': 3,\n",
       " 'puta': 3,\n",
       " 'excelente': 2,\n",
       " 'saudável': 1,\n",
       " 'catarse': 1,\n",
       " 'aliás': 12,\n",
       " 'mesmo': 3,\n",
       " 'oxigene': 1,\n",
       " 'maoleskine': 1,\n",
       " 'maratonar': 1,\n",
       " 'breve': 1,\n",
       " 'again': 1,\n",
       " 'primeira': 1,\n",
       " 'lançamento': 1,\n",
       " 'determina': 1,\n",
       " 'quanto': 1,\n",
       " 'cartaz': 20,\n",
       " 'essa': 3,\n",
       " 'lançado': 1,\n",
       " 'maravilhoso': 1,\n",
       " 'mundo': 9,\n",
       " 'sério': 1,\n",
       " 'brasileiros': 1,\n",
       " '❤': 1,\n",
       " '️': 4,\n",
       " 'sopranine': 1,\n",
       " 'ali': 1,\n",
       " 'juntas': 1,\n",
       " 'moskito': 1,\n",
       " 'recebendo': 1,\n",
       " 'mandar': 1,\n",
       " 'grupo': 1,\n",
       " 'dividido': 1,\n",
       " 'amou': 1,\n",
       " 'odiou': 1,\n",
       " 'idosas': 1,\n",
       " 'estavam': 1,\n",
       " 'gostaram': 1,\n",
       " 'admitiram': 1,\n",
       " 'bem': 15,\n",
       " 'feito': 1,\n",
       " 'wotzik': 1,\n",
       " 'brasil': 9,\n",
       " 'urgente': 1,\n",
       " 'vivam': 1,\n",
       " 'necessário': 1,\n",
       " 'iskindolele': 1,\n",
       " 'estava': 2,\n",
       " 'obcecado': 1,\n",
       " 'passava': 1,\n",
       " '80': 1,\n",
       " 'outros': 1,\n",
       " 'torcia': 1,\n",
       " 'falasse': 1,\n",
       " 'sobre…': 1,\n",
       " 'porém': 1,\n",
       " 'afirmo': 1,\n",
       " 'tranquilidade': 1,\n",
       " 'milenio': 1,\n",
       " 'veja': 7,\n",
       " 'molena': 1,\n",
       " 'incentive': 1,\n",
       " 'nacional': 2,\n",
       " 'meter': 1,\n",
       " 'doido': 1,\n",
       " 'logo': 1,\n",
       " 'iguatemi': 1,\n",
       " 'antes': 8,\n",
       " 'fique': 1,\n",
       " 'sem': 1,\n",
       " 'minh': 1,\n",
       " 'dando': 1,\n",
       " 'palestra': 1,\n",
       " 'pessoal': 1,\n",
       " 'fez': 4,\n",
       " 'trilha': 8,\n",
       " 'sonora': 7,\n",
       " 'mimos': 1,\n",
       " 'pai': 2,\n",
       " 'aquelacristiana': 1,\n",
       " 'fãs': 1,\n",
       " '=': 1,\n",
       " 'melhores': 2,\n",
       " 'parece': 3,\n",
       " 'infinitamente': 1,\n",
       " 'interessante': 1,\n",
       " 'rodrigoazo': 1,\n",
       " 'olha': 1,\n",
       " 'motivo': 1,\n",
       " 'vermos': 1,\n",
       " 'filmaço': 1,\n",
       " 'ode': 1,\n",
       " 'nosso': 2,\n",
       " 'sobretudo': 1,\n",
       " 'valente': 1,\n",
       " 'povo': 2,\n",
       " 'nordestino': 2,\n",
       " 'sensação': 1,\n",
       " 'reencontro': 1,\n",
       " 'cultura': 3,\n",
       " 'retrato': 1,\n",
       " 'histórico': 1,\n",
       " 'majestoso': 1,\n",
       " 'viva': 2,\n",
       " 'chegou': 2,\n",
       " 'jundiaí': 1,\n",
       " 'sexo': 1,\n",
       " 'sagrado': 1,\n",
       " 'seu': 2,\n",
       " 'corpo': 1,\n",
       " 'templo': 1,\n",
       " 'compartilhá': 1,\n",
       " 'louca': 1,\n",
       " 'sozinha': 1,\n",
       " 'msm': 1,\n",
       " 'dragão': 1,\n",
       " 'sigur_ross_': 1,\n",
       " 'arrasta': 1,\n",
       " 'maxxxramon': 2,\n",
       " 'choque': 1,\n",
       " 'tbt': 1,\n",
       " 'assista': 5,\n",
       " 'crítica': 3,\n",
       " 'arrobanerd': 1,\n",
       " 'longa': 1,\n",
       " 'traz': 1,\n",
       " 'reviravoltas': 1,\n",
       " 'tirar': 1,\n",
       " 'fôlego': 1,\n",
       " 'paulo__junior__': 12,\n",
       " 'ignorou': 1,\n",
       " 'som': 2,\n",
       " 'redor': 3,\n",
       " 'principal': 1,\n",
       " 'resistia': 1,\n",
       " 'exatamente': 1,\n",
       " 'rasteira': 1,\n",
       " 'contraditório': 1,\n",
       " 'nas': 1,\n",
       " 'ideias': 1,\n",
       " 'escreve': 1,\n",
       " 'saber': 1,\n",
       " 'metáfora': 1,\n",
       " 'p': 4,\n",
       " 'gyn': 1,\n",
       " 'tô': 20,\n",
       " 'lembrando': 1,\n",
       " 'cena': 1,\n",
       " 'fala': 1,\n",
       " 'personagens': 2,\n",
       " 'sob': 1,\n",
       " 'efeito': 1,\n",
       " 'forte': 8,\n",
       " 'psicotrópico': 1,\n",
       " 'morrer': 2,\n",
       " 'hauahuahuahuhauauuahuahuauuahuahhuahuauuahuahhuahuauuahuah': 1,\n",
       " 'camisetinha': 1,\n",
       " 'temos': 1,\n",
       " 'so': 1,\n",
       " '1': 6,\n",
       " 'pessoa': 6,\n",
       " 'reclamando': 2,\n",
       " 'alguma': 1,\n",
       " 'boyzinha': 1,\n",
       " 'xuliaxx': 1,\n",
       " 'zap': 1,\n",
       " 'conversar': 1,\n",
       " 'seguinte': 1,\n",
       " 'eupalmeirensa': 2,\n",
       " 'laianexx': 1,\n",
       " 'laiane': 1,\n",
       " 'quer': 6,\n",
       " 'morenamoraes': 1,\n",
       " 'abruxapreta': 1,\n",
       " 'cinemarkoficial': 1,\n",
       " 'querendo': 1,\n",
       " 'salas': 2,\n",
       " 'posso': 1,\n",
       " 'abre': 1,\n",
       " 'nenhuma': 1,\n",
       " 'h4ckaq': 2,\n",
       " 'dor': 2,\n",
       " 'cabeça': 2,\n",
       " 'enjoo': 1,\n",
       " 'vontade': 2,\n",
       " 'ressaca': 2,\n",
       " 'diálogos': 1,\n",
       " 'companhia': 1,\n",
       " 'sincera': 1,\n",
       " 'tomar': 18,\n",
       " 'açaí': 1,\n",
       " 'verdade': 1,\n",
       " 'beber': 1,\n",
       " 'aff': 5,\n",
       " 'sinopse': 1,\n",
       " 'interessou': 1,\n",
       " 'bastante': 1,\n",
       " 'lucasnunnes97': 1,\n",
       " '_msoliveira': 1,\n",
       " 'processando': 1,\n",
       " 'tanta': 1,\n",
       " 'atualmente': 1,\n",
       " 'gastei': 1,\n",
       " 'chance': 1,\n",
       " 'vendo': 2,\n",
       " 'aquela': 1,\n",
       " 'tranqueira': 1,\n",
       " 'incrível': 1,\n",
       " 'adjetivos': 1,\n",
       " 'qualidade': 2,\n",
       " 'deveriam': 1,\n",
       " 'provavelmente': 2,\n",
       " 'ja': 3,\n",
       " 'cinemark': 2,\n",
       " 'então': 4,\n",
       " 'cuiabano': 1,\n",
       " 'prestigiar': 1,\n",
       " 'hein': 1,\n",
       " 'faltava': 1,\n",
       " 'unisse': 1,\n",
       " 'todas': 1,\n",
       " 'tribos': 1,\n",
       " 'pablomoreno': 1,\n",
       " 'amei': 7,\n",
       " 'sertão': 1,\n",
       " 'impacto': 1,\n",
       " 'lucidez': 1,\n",
       " 'realização': 1,\n",
       " 'precisa': 5,\n",
       " 'digerir': 1,\n",
       " 'após': 1,\n",
       " 'muitos': 1,\n",
       " 'elogios': 1,\n",
       " 'espero': 1,\n",
       " 'encante': 1,\n",
       " 'hj': 2,\n",
       " 'assisto': 1,\n",
       " 'refrescos': 1,\n",
       " 'agenda': 1,\n",
       " 'conturbada': 1,\n",
       " 'parça': 2,\n",
       " '♥': 1,\n",
       " 'meio': 1,\n",
       " 'loucura': 1,\n",
       " 'assistido': 1,\n",
       " 'mandei': 1,\n",
       " 'tweet': 2,\n",
       " 'mauromendoncaf': 1,\n",
       " 'engravidar': 1,\n",
       " 'louco': 1,\n",
       " 'tesao': 1,\n",
       " 'sendo': 2,\n",
       " 'socorro': 1,\n",
       " 'dizer': 1,\n",
       " '“amiga': 1,\n",
       " 'juntas”': 1,\n",
       " 'supero': 1,\n",
       " 'aniversario': 1,\n",
       " 'paga': 1,\n",
       " 'única': 1,\n",
       " 'entendi': 1,\n",
       " 'ns': 2,\n",
       " 'this': 2,\n",
       " 'is': 2,\n",
       " 'homofobia': 2,\n",
       " 'filhudi': 1,\n",
       " 'filhusi': 1,\n",
       " 'brasilia': 1,\n",
       " 'w': 1,\n",
       " 'fé': 1,\n",
       " 'poder': 1,\n",
       " 'fernanda': 1,\n",
       " 'reservando': 1,\n",
       " 'são': 8,\n",
       " 'luiz': 1,\n",
       " 'alunos': 1,\n",
       " '🤧': 1,\n",
       " '🥰': 1,\n",
       " '😭': 1,\n",
       " 'óbvio': 3,\n",
       " 'enfiar': 1,\n",
       " 'obra': 1,\n",
       " 'inspira': 1,\n",
       " 'maravilha': 1,\n",
       " 'silveropereira': 1,\n",
       " 'votei': 1,\n",
       " 'assistiria': 1,\n",
       " 'hora': 2,\n",
       " 'penso': 1,\n",
       " 'perplexo': 1,\n",
       " 'recorte': 2,\n",
       " 'irregular': 2,\n",
       " 'obsessões': 2,\n",
       " 'exportação': 2,\n",
       " 'comentar': 1,\n",
       " 'realidade': 1,\n",
       " 'amigas': 1,\n",
       " 'essas': 1,\n",
       " 'histórias': 1,\n",
       " 'itimalian': 1,\n",
       " 'bacurit': 1,\n",
       " 'kkkkk': 2,\n",
       " 'aaa': 1,\n",
       " 'filha': 4,\n",
       " 'pois': 2,\n",
       " 'trate': 1,\n",
       " 'cinem': 1,\n",
       " 'volta': 3,\n",
       " 'agoraaaaaaa': 1,\n",
       " 'viaverdeshop': 1,\n",
       " 'amiguinho': 1,\n",
       " 'queira': 1,\n",
       " 'preferência': 1,\n",
       " 'segunda': 2,\n",
       " 'quarta': 4,\n",
       " 'preço': 1,\n",
       " 'promocional': 1,\n",
       " 'postando': 2,\n",
       " 'plena': 1,\n",
       " 'convicção': 1,\n",
       " 'flop': 1,\n",
       " 'citar': 1,\n",
       " 'correntes': 1,\n",
       " 'além': 2,\n",
       " 'central': 1,\n",
       " 'ela': 10,\n",
       " 'amanhã': 3,\n",
       " 'mesa': 1,\n",
       " 'buteco': 1,\n",
       " 'centro': 1,\n",
       " 'cmggg': 1,\n",
       " 'algm': 1,\n",
       " 'hd5trange': 1,\n",
       " 'nice': 1,\n",
       " 'comprando': 1,\n",
       " 'ingresso': 4,\n",
       " 'naquelas': 1,\n",
       " 'máquinas': 1,\n",
       " 'deu': 2,\n",
       " 'gritar': 1,\n",
       " 'filmão': 1,\n",
       " 'caray': 1,\n",
       " 'onde': 2,\n",
       " 'refletir': 1,\n",
       " 'virá': 1,\n",
       " 'escolas': 1,\n",
       " 'museus': 1,\n",
       " 'sentido': 1,\n",
       " 'literal': 1,\n",
       " 'figurado': 1,\n",
       " 'tentar': 1,\n",
       " 'recuperar': 1,\n",
       " 'projeto': 2,\n",
       " 'entregar': 1,\n",
       " 'rever': 1,\n",
       " 'dressasantiago_': 1,\n",
       " 'diferenciado': 1,\n",
       " 'chamaram': 1,\n",
       " 'estamos': 2,\n",
       " 'evoluindo': 1,\n",
       " 'caionare4l': 1,\n",
       " 'vim': 5,\n",
       " 'humildemente': 1,\n",
       " 'irem': 2,\n",
       " 'assitir': 1,\n",
       " 'perfeitooo': 1,\n",
       " 'iamplanett': 2,\n",
       " 'atenção': 2,\n",
       " '22': 2,\n",
       " '09': 2,\n",
       " 'passar': 11,\n",
       " 'vitória': 3,\n",
       " 'opção': 2,\n",
       " 'barata': 2,\n",
       " 'local…': 1,\n",
       " 'bacuraufilme': 13,\n",
       " 'façam': 2,\n",
       " 'teste': 4,\n",
       " 'domingas': 36,\n",
       " 'orgulho': 2,\n",
       " 'objetivos': 9,\n",
       " 'cumpridos': 2,\n",
       " 'beareclama': 1,\n",
       " 'kkkk': 2,\n",
       " 'falta': 2,\n",
       " 'pacote': 18,\n",
       " 'teresa': 17,\n",
       " 'pospunkcearense': 1,\n",
       " 'tabacaria': 2,\n",
       " 'impossível': 2,\n",
       " 'inagaki': 15,\n",
       " 'virar': 15,\n",
       " 'sou': 15,\n",
       " 'via': 4,\n",
       " 'davirocha': 1,\n",
       " 'bluecoloredboy': 2,\n",
       " 'conte': 2,\n",
       " 'amo': 9,\n",
       " 'socorr': 1,\n",
       " 'kkkkkkk': 2,\n",
       " 'tirou': 9,\n",
       " 'própria': 17,\n",
       " 'cidade': 18,\n",
       " 'amigável': 11,\n",
       " 'pacífica': 11,\n",
       " 'tentando': 11,\n",
       " 'atrapalhar': 11,\n",
       " 'sua': 20,\n",
       " 'obrigada': 11,\n",
       " 'próprias': 11,\n",
       " 'rédeas': 11,\n",
       " 'destino': 11,\n",
       " 'continuar': 11,\n",
       " 'sobrevivendo': 11,\n",
       " 'omegamark_xii': 5,\n",
       " 'te': 7,\n",
       " 'agostinho': 9,\n",
       " 'carrara': 5,\n",
       " 'matar': 6,\n",
       " 'carara': 5,\n",
       " 'matemática': 5,\n",
       " 'basica': 5,\n",
       " 'marque': 5,\n",
       " 'ami…': 1,\n",
       " 'ifavmarkten': 2,\n",
       " 'tive': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for palavra in lista_irrelevante:\n",
    "    freq_irr[palavra]+=1\n",
    "freq_irr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do Naive Bayes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso foi utilizado o teorema de Bayes:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "P(relevância|palavra) = \\frac{P(palavra|relevância)P(relevância)}{P(palavra)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_irr = {}\n",
    "prob_rel = {}\n",
    "\n",
    "for palavra in palavras_totais:\n",
    "    prob_rel[palavra]= freq_rel[palavra]/(len(palavras_totais)+quantidade_relevancia[1])\n",
    "    prob_irr[palavra]= freq_irr[palavra]/(len(palavras_totais)+quantidade_relevancia[0])\n",
    "    \n",
    "\n",
    "#probabilidade da relevância em relação às palavras do tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora vamos testar o classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alguém me convida pra assistir bacurau amanhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kmendoncafilho as duas sessoes de bacurau hj ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cinearteuff bacurau tem entranhas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>não é possível que bacurau já esteja disponíve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>só vou ver bacurau domingo boe  alguma gay pod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Relevância\n",
       "0     alguém me convida pra assistir bacurau amanhã            1\n",
       "1   kmendoncafilho as duas sessoes de bacurau hj ...           1\n",
       "2               cinearteuff bacurau tem entranhas              1\n",
       "3  não é possível que bacurau já esteja disponíve...           0\n",
       "4  só vou ver bacurau domingo boe  alguma gay pod...           0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_df = pd.DataFrame()\n",
    "teste_df[\"Tweets\"] = teste_limpo\n",
    "teste_df[\"Relevância\"] = teste[\"Relevância\"]\n",
    "\n",
    "teste_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Relevância</th>\n",
       "      <th>Chutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alguém me convida pra assistir bacurau amanhã</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kmendoncafilho as duas sessoes de bacurau hj ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cinearteuff bacurau tem entranhas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>não é possível que bacurau já esteja disponíve...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>só vou ver bacurau domingo boe  alguma gay pod...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Relevância  Chutes\n",
       "0     alguém me convida pra assistir bacurau amanhã            1       0\n",
       "1   kmendoncafilho as duas sessoes de bacurau hj ...           1       0\n",
       "2               cinearteuff bacurau tem entranhas              1       0\n",
       "3  não é possível que bacurau já esteja disponíve...           0       0\n",
       "4  só vou ver bacurau domingo boe  alguma gay pod...           0       0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chutes = [] #lista com chutes baseados nas probabilidades\n",
    "for tweet in teste_limpo:\n",
    "    pI = 1\n",
    "    pR = 1\n",
    "    palavras = tweet.split(\" \")\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        if palavra in prob_rel:\n",
    "            pR*= prob_rel[palavra]\n",
    "        else:\n",
    "            pR *= 1/(len(palavras_totais)+quantidade_relevancia[1])\n",
    "        if palavra in prob_irr:\n",
    "            pI*= prob_irr[palavra]\n",
    "        else:\n",
    "            pI *= 1/(len(palavras_totais)+quantidade_relevancia[0])\n",
    "    \n",
    "    Prob_Rel = quantidade_relevancia[1]*pR\n",
    "    Prob_Irr = quantidade_relevancia[0]*pI\n",
    "    \n",
    "    if Prob_Rel>= Prob_Irr:\n",
    "        chutes.append(1)\n",
    "    else:\n",
    "        chutes.append(0)\n",
    "#     print (Prob_Irr)\n",
    "        \n",
    "\n",
    "teste_df[\"Chutes\"]=chutes\n",
    "teste_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_certo = teste_df.loc[(teste_df['Relevância']==1)&(teste_df['Chutes']==1), ['Relevância','Chutes']]\n",
    "rel_err = teste_df.loc[(teste_df['Relevância']!=1)&(teste_df['Chutes']==1), ['Relevância','Chutes']]\n",
    "irr_certo = teste_df.loc[(teste_df['Relevância']==0)&(teste_df['Chutes']==0), ['Relevância','Chutes']]\n",
    "irr_err = teste_df.loc[(teste_df['Relevância']!=0)&(teste_df['Chutes']==0), ['Relevância','Chutes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fizemos um *crosstab* para comparar os resultados dados com os resultados previstos pelo treinamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Treinamento</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Treinamento       0     1   All\n",
       "Classificação                  \n",
       "0              0.38  0.00  0.38\n",
       "1              0.58  0.04  0.62\n",
       "All            0.96  0.04  1.00"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_sudoku = pd.crosstab(teste_df[\"Relevância\"], teste_df[\"Chutes\"], rownames=[\"Classificação\"], colnames=[\"Treinamento\"], margins=True, normalize=True)\n",
    "tabela_sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevantes corretos: 4.0%\n",
      "Irrelevantes corretos: 38.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Relevantes corretos: {0}%\".format((tabela_sudoku.loc[1,1])*100))\n",
    "print(\"Irrelevantes corretos: {0}%\".format((tabela_sudoku.loc[0,0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que nosso classificador marcou 4% dos *tweets* como relevantes quando eles realmente eram relevantes e 38% como irrelevantes corretamente. Esses valores representam que nosso classificador ainda precisa de ajustes e melhorias para que se torne mais preciso. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperfeiçoamento:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o Naive Bayes não considera a correlação entre as palavras, poderiamos fazer um programa que fizesse a combinação entre elas para desenvolver um classificador ainda mais preciso. Por exemplo, poderiamos combinar as palavras \"não\" e \"melhor\", para que o computador não classifique erroneamente um *tweet* que esteja dizendo: \"Bacurau não é o melhor filme que eu já assisti\" como relevante, apenas porque apresenta a palavra \"melhor\" nele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  \n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) \n",
    "\n",
    "[Techniques for Improving the Performance\n",
    "of Naive Bayes for Text Classification](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.2085&rep=rep1&type=pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
